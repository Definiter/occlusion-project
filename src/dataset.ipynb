{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object occluders loaded.\n",
      "Processing synset [1/1000], image [50/150]: n01491361_3737\n",
      "Processing synset [1/1000], image [100/150]: n01491361_899\n",
      "Processing synset [1/1000], image [150/150]: n01491361_3104\n",
      "Processing synset [2/1000], image [50/150]: n07760859_3234\n",
      "Processing synset [2/1000], image [100/150]: n07760859_8130\n",
      "Processing synset [2/1000], image [150/150]: n07760859_8359\n",
      "Processing synset [3/1000], image [50/150]: n03494278_30285\n",
      "Processing synset [3/1000], image [100/150]: n03494278_41142\n",
      "Processing synset [3/1000], image [150/150]: n03494278_10534\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f65ac09c92d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mrects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mimg_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msynset_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mintersection_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.JPEG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'1k'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtype_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/haow3/miniconda2/envs/cafferc3/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2278\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2280\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%file dataset.py\n",
    "# Generate training dataset and test dataset.\n",
    "from constant import *\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "\n",
    "#### Parameters. ####\n",
    "type_str = '1k_crop_obj' # {1k_}[crop | nocrop | crop_obj | nocrop_obj | aperture]\n",
    "\n",
    "#dataset = [(0.0, 0), (1.0/4, 4), (1.0/3, 3), (1.0/2, 3), (2.0/3, 3), (4.0/5, 3), (9.0/10, 3), (1.0, 1)]\n",
    "#dataset = [(0.0, 0), (0.1, 10), (0.2, 5), (0.3, 4), (0.4, 3), (0.5, 3), (0.6, 3), (0.7, 3), (0.8, 3), (0.9, 3), (1.0, 1)]\n",
    "dataset = [(0.0, 0), (0.2, 9), (0.4, 9), (0.6, 9), (0.8, 9), (1.0, 9)] # when crop_obj or nocrop_obj, (size, total_num)\n",
    "\n",
    "# divide to training dataset and test dataset\n",
    "training_dataset_size = 100\n",
    "test_dataset_size = 50\n",
    "\n",
    "# obj image: always 1024 * 768 pixels\n",
    "obj_width = 1024\n",
    "obj_height = 768\n",
    "obj_ratio = float(obj_width) / obj_height\n",
    "#####################\n",
    "\n",
    "# Load labels.\n",
    "imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "label_to_wnid = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "training_dataset = dataset\n",
    "test_dataset = dataset\n",
    "\n",
    "train_folders = []\n",
    "test_folders = []\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "for (slider_size, slider_num) in training_dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/train_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    train_files.append(f)\n",
    "    \n",
    "    folder = '{}dataset/train_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    train_folders.append(folder)\n",
    "        \n",
    "\n",
    "for (slider_size, slider_num) in test_dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/test_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    test_files.append(f)\n",
    "\n",
    "    folder = '{}dataset/test_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    test_folders.append(folder)\n",
    "    \n",
    "if 'obj' in type_str:\n",
    "    obj_images = []\n",
    "    for i, image_name in enumerate(os.listdir(shapenet_root + 'object_nobg/')):\n",
    "        print i\n",
    "        img_temp = Image.open(shapenet_root + 'object_nobg/' + image_name)\n",
    "        img = copy.copy(img_temp)\n",
    "        img_temp.close()\n",
    "        #img = img.convert(\"RGBA\")\n",
    "        obj_images.append(img)\n",
    "print \"Object occluders loaded.\"\n",
    "\n",
    "# occluder size = slider_size * slider_size\n",
    "# occluder num = slider_num * slider_num\n",
    "# path = 'imagenet_root/dataset/train_0/name'\n",
    "# {wnid_imgid}_{crop/nocrop}_{rect_i(ifcrop)}_{slider_size}_{i}_{j}\n",
    "def generate_datum(img_orig, path, f, class_id, rects, slider_size, slider_num):\n",
    "    if type_str == 'crop' or type_str == '1k_crop':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = copy.copy(img_orig)\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_0_0_0.jpeg'.format(path, type_str, rect_i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    for j in range(slider_num):\n",
    "                        img = copy.copy(img_orig)\n",
    "                        d = ImageDraw.Draw(img)\n",
    "                        if (slider_num == 1):\n",
    "                            delta = 1\n",
    "                        else:\n",
    "                            delta = (1 - slider_size) / float(slider_num - 1)\n",
    "                        subrect = [0, 0, 0, 0]\n",
    "                        subrect[0] = rect[0] + i * (rect[2] - rect[0]) * delta\n",
    "                        subrect[1] = rect[1] + j * (rect[3] - rect[1]) * delta\n",
    "                        subrect[2] = subrect[0] + (rect[2] - rect[0]) * slider_size\n",
    "                        subrect[3] = subrect[1] + (rect[3] - rect[1]) * slider_size\n",
    "                        d.rectangle(subrect, fill=\"black\", outline=None)\n",
    "                        img = img.crop(rect)\n",
    "                        datum_path = '{}_{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), str(i), str(j))\n",
    "                        img.save(datum_path)\n",
    "                        f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "    if type_str == 'nocrop' or type_str == '1k_nocrop':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_0_0_0_0.jpeg'.format(path, type_str)\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for i in range(slider_num):\n",
    "                for j in range(slider_num):\n",
    "                    img = copy.copy(img_orig)\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    if (slider_num == 1):\n",
    "                        delta = 1\n",
    "                    else:\n",
    "                        delta = (1 - slider_size) / float(slider_num - 1)\n",
    "                    for rect in rects:\n",
    "                        subrect = [0, 0, 0, 0]\n",
    "                        subrect[0] = rect[0] + i * (rect[2] - rect[0]) * delta\n",
    "                        subrect[1] = rect[1] + j * (rect[3] - rect[1]) * delta\n",
    "                        subrect[2] = subrect[0] + (rect[2] - rect[0]) * slider_size\n",
    "                        subrect[3] = subrect[1] + (rect[3] - rect[1]) * slider_size\n",
    "                        d.rectangle(subrect, fill=\"black\", outline=None)\n",
    "                    datum_path = '{}_{}_{}_{}_{}_{}.jpeg'.format(path, type_str, 0, str(int(100 * slider_size)), str(i), str(j))\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))                    \n",
    "    \n",
    "    if type_str == 'crop_obj' or type_str == '1k_crop_obj':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = copy.copy(img_orig)\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, int(100 * slider_size))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for num in range(slider_num):\n",
    "                    img = copy.copy(img_orig)\n",
    "                    random_obj = copy.copy(obj_images[random.randint(0, len(obj_images) - 1)])\n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    if ratio >= obj_ratio:\n",
    "                        resize_scale = float(height) / obj_height * slider_size\n",
    "                    else:\n",
    "                        resize_scale = float(width) / obj_width * slider_size\n",
    "                    random_obj = random_obj.resize((int(obj_width * resize_scale), int(obj_height * resize_scale)), Image.ANTIALIAS)\n",
    "                    top_left = (random.randint(rect[0], rect[2] - random_obj.size[0]), \\\n",
    "                                random.randint(rect[1], rect[3] - random_obj.size[1]))\n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "                    \n",
    "    if type_str == 'nocrop_obj' or type_str == '1k_nocrop_obj':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, 0, int(100 * slider_size))\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for num in range(slider_num):\n",
    "                img = copy.copy(img_orig)\n",
    "                for rect_i, rect in enumerate(rects):\n",
    "                    random_obj = copy.copy(obj_images[random.randint(0, len(obj_images) - 1)])\n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    if ratio >= obj_ratio:\n",
    "                        resize_scale = float(height) / obj_height * slider_size\n",
    "                    else:\n",
    "                        resize_scale = float(width) / obj_width * slider_size\n",
    "                    random_obj = random_obj.resize((int(obj_width * resize_scale), int(obj_height * resize_scale)), Image.ANTIALIAS)\n",
    "                    top_left = (random.randint(rect[0], rect[2] - random_obj.size[0]), \\\n",
    "                                random.randint(rect[1], rect[3] - random_obj.size[1]))\n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))              \n",
    "                    \n",
    "                    \n",
    "    if type_str == 'aperture' or type_str == '1k_aperture':\n",
    "        if slider_size == 0: # All black.\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = copy.copy(img_orig)\n",
    "                d = ImageDraw.Draw(img)\n",
    "                d.rectangle(rect, fill=\"black\", outline=None)\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        elif slider_size == 1: # All visible. \n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = copy.copy(img_orig)\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    for j in range(slider_num):\n",
    "                        img = copy.copy(img_orig)\n",
    "                        d = ImageDraw.Draw(img)\n",
    "                        delta = (1 - slider_size) / float(slider_num - 1)\n",
    "                        subrect = [0, 0, 0, 0]\n",
    "                        subrect[0] = rect[0] + i * (rect[2] - rect[0]) * delta\n",
    "                        subrect[1] = rect[1] + j * (rect[3] - rect[1]) * delta\n",
    "                        subrect[2] = subrect[0] + (rect[2] - rect[0]) * slider_size\n",
    "                        subrect[3] = subrect[1] + (rect[3] - rect[1]) * slider_size\n",
    "                        d.rectangle([0, 0, img.size[0], subrect[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([0, 0, subrect[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([subrect[2], 0, img.size[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([0, subrect[3], img.size[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        img = img.crop(rect)\n",
    "                        datum_path = '{}_{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), str(i), str(j))\n",
    "                        img.save(datum_path)\n",
    "                        f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "            \n",
    "if '1k' in type_str:\n",
    "    image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "    annotation_path =  imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/'\n",
    "else:\n",
    "    image_path = imagenet_root + 'image/'\n",
    "    annotation_path = imagenet_root + 'Annotation/'\n",
    "\n",
    "synset_names = os.listdir(image_path)\n",
    "             \n",
    "for synset_index, synset_name in enumerate(synset_names):\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    annotation_names = os.listdir(annotation_path + synset_name)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    dataset_sum = training_dataset_size + test_dataset_size\n",
    "    for i in range(dataset_sum):\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print 'Processing synset [{}/{}], image [{}/{}]: {}'.format(synset_index + 1, len(synset_names), i + 1, dataset_sum, intersection_names[i])\n",
    "        # Read bounding box.\n",
    "        bbx_file = open(annotation_path + synset_name + '/' + intersection_names[i] + '.xml')\n",
    "        xmltree = ET.parse(bbx_file)\n",
    "        objects = xmltree.findall('object')\n",
    "        rects = []\n",
    "        for obj in objects:\n",
    "            bbx = obj.find('bndbox')\n",
    "            rects.append([int(it.text) for it in bbx])\n",
    "            \n",
    "        img_orig = Image.open(image_path + synset_name + '/' + intersection_names[i] + '.JPEG')\n",
    "        \n",
    "        if '1k' in type_str:\n",
    "            class_id = wnid_to_label[synset_name]\n",
    "        else:\n",
    "            class_id = original_to_new_class_id[wnid_to_label[synset_name]]\n",
    "        \n",
    "        if i < training_dataset_size: # Training dataset. \n",
    "            for index, (slider_size, slider_num) in enumerate(training_dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(train_folders[index], intersection_names[i]), \\\n",
    "                               train_files[index], class_id, rects, slider_size, slider_num)\n",
    "        else: # Testing dataset.\n",
    "            for index, (slider_size, slider_num) in enumerate(test_dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(test_folders[index], intersection_names[i]), \\\n",
    "                               test_files[index], class_id, rects, slider_size, slider_num)\n",
    "            \n",
    "for f in train_files:\n",
    "    f.close()\n",
    "for f in test_files:\n",
    "    f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample.\n",
    "\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "\n",
    "need_samples = ['10', '20', '30']\n",
    "\n",
    "type_str = 'aperture'\n",
    "sample_sum = 62316\n",
    "\n",
    "# train\n",
    "'''\n",
    "for need_sample in need_samples:\n",
    "    os.rename('{}dataset/train_{}_{}.txt'.format(imagenet_root, type_str, need_sample), '{}dataset/train_{}_{}_unsampled.txt'.format(imagenet_root, type_str, need_sample))\n",
    "    f = open('{}dataset/train_{}_{}_unsampled.txt'.format(imagenet_root, type_str, need_sample), 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    sampled = random.sample(lines, sample_sum)\n",
    "    f = open('{}dataset/train_{}_{}.txt'.format(imagenet_root, type_str, need_sample), 'w')\n",
    "    f.writelines(sampled)\n",
    "    f.close()\n",
    "'''\n",
    "# test\n",
    "for need_sample in need_samples:\n",
    "    os.rename('{}dataset/test_{}_{}.txt'.format(imagenet_root, type_str, need_sample), '{}dataset/test_{}_{}_unsampled.txt'.format(imagenet_root, type_str, need_sample))\n",
    "    f = open('{}dataset/test_{}_{}_unsampled.txt'.format(imagenet_root, type_str, need_sample), 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    sampled = random.sample(lines, 21168)\n",
    "    f = open('{}dataset/test_{}_{}.txt'.format(imagenet_root, type_str, need_sample), 'w')\n",
    "    f.writelines(sampled)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create all.\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "\n",
    "dataset = [(0.0, 0), (0.2, 9), (0.4, 9), (0.6, 9), (0.8, 9), (1.0, 9)] # when crop_obj or nocrop_obj, (size, total_num)\n",
    "\n",
    "sample_sum = {'train': {'crop_obj': 62316, 'nocrop_obj': 54000}, \\\n",
    "              'test': {'crop_obj': 21168, 'nocrop_obj': 18000}}\n",
    "\n",
    "# train_{}_all\n",
    "for type_str in ['crop_obj', 'nocrop_obj']:\n",
    "    for func_str in ['train', 'test']:\n",
    "        lines = []\n",
    "        for size, num in dataset:\n",
    "            percent = int(size * 100)\n",
    "            f = open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, percent), 'r')\n",
    "            ls = f.readlines()\n",
    "            f.close()\n",
    "            lines = lines + ls\n",
    "        f = open('{}dataset/{}_{}_all_unsampled.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        sampled = random.sample(lines, sample_sum[func_str][type_str])\n",
    "        f = open('{}dataset/{}_{}_all.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(sampled)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transparent.py\n"
     ]
    }
   ],
   "source": [
    "%%file transparent.py\n",
    "# Make white color transparent.\n",
    "from constant import *\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_names = os.listdir(shapenet_root + 'object_orig/')\n",
    "print len(image_names)\n",
    "\n",
    "for i, image_name in enumerate(image_names):\n",
    "    print '[{}/{}]: {}'.format(i, 10000, image_name)\n",
    "    img = Image.open(shapenet_root + 'object_orig/' + image_name)\n",
    "    \n",
    "    img = img.convert(\"RGBA\")\n",
    "    pixdata = img.load()\n",
    "    for y in xrange(img.size[1]):\n",
    "        for x in xrange(img.size[0]):\n",
    "            if pixdata[x, y] == (255, 255, 255, 255):\n",
    "                pixdata[x, y] = (255, 255, 255, 0)\n",
    "    img.save(shapenet_root + 'object_nobg/' + image_name, 'PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show typical images of each class.\n",
    "from constant import *\n",
    "import os\n",
    "import numpy as np\n",
    "#from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "with open(imagenet_labels_filename) as f:\n",
    "    lines = f.readlines()\n",
    "wnid_to_name = {}\n",
    "for line in lines:\n",
    "    wnid = line.split(' ')[0]\n",
    "    name = line[(len(wnid) + 1):-1]\n",
    "    wnid_to_name[wnid] = name\n",
    "\n",
    "synset_names = os.listdir(imagenet_root + 'image/')\n",
    "for synset_name in synset_names:\n",
    "    image_names = os.listdir(imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images')\n",
    "    print wnid_to_name[synset_name], 'http://image-net.org/synset?wnid=' + synset_name\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[42]))\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[32]))\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[22]))\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[12]))\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[0]))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 /data2/haow3/data/imagenet/dataset/train_nocrop_obj_0\n",
      "54000 /data2/haow3/data/imagenet/dataset/train_nocrop_obj_20\n",
      "54000 /data2/haow3/data/imagenet/dataset/train_nocrop_obj_40\n",
      "54000 /data2/haow3/data/imagenet/dataset/train_nocrop_obj_60\n",
      "54000 /data2/haow3/data/imagenet/dataset/train_nocrop_obj_80\n",
      "54000 /data2/haow3/data/imagenet/dataset/train_nocrop_obj_100\n",
      "6924 /data2/haow3/data/imagenet/dataset/train_crop_obj_0\n",
      "62316 /data2/haow3/data/imagenet/dataset/train_crop_obj_20\n",
      "62316 /data2/haow3/data/imagenet/dataset/train_crop_obj_40\n",
      "62316 /data2/haow3/data/imagenet/dataset/train_crop_obj_60\n",
      "62316 /data2/haow3/data/imagenet/dataset/train_crop_obj_80\n",
      "62316 /data2/haow3/data/imagenet/dataset/train_crop_obj_100\n",
      "2000 /data2/haow3/data/imagenet/dataset/test_nocrop_obj_0\n",
      "18000 /data2/haow3/data/imagenet/dataset/test_nocrop_obj_20\n",
      "18000 /data2/haow3/data/imagenet/dataset/test_nocrop_obj_40\n",
      "18000 /data2/haow3/data/imagenet/dataset/test_nocrop_obj_60\n",
      "18000 /data2/haow3/data/imagenet/dataset/test_nocrop_obj_80\n",
      "18000 /data2/haow3/data/imagenet/dataset/test_nocrop_obj_100\n",
      "2352 /data2/haow3/data/imagenet/dataset/test_crop_obj_0\n",
      "21168 /data2/haow3/data/imagenet/dataset/test_crop_obj_20\n",
      "21168 /data2/haow3/data/imagenet/dataset/test_crop_obj_40\n",
      "21168 /data2/haow3/data/imagenet/dataset/test_crop_obj_60\n",
      "21168 /data2/haow3/data/imagenet/dataset/test_crop_obj_80\n",
      "21168 /data2/haow3/data/imagenet/dataset/test_crop_obj_100\n"
     ]
    }
   ],
   "source": [
    "# Sanity check.\n",
    "import os\n",
    "from constant import *\n",
    "\n",
    "func_strs = ['train', 'test']\n",
    "type_strs = ['nocrop_obj', 'crop_obj']\n",
    "dataset = [(0.0, 0), (0.2, 9), (0.4, 9), (0.6, 9), (0.8, 9), (1.0, 9)] # when crop_obj or nocrop_obj, (size, total_num)\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        for size, num in dataset:\n",
    "            percent = int(size * 100)\n",
    "            path = imagenet_root + 'dataset/{}_{}_{}'.format(func_str, type_str, percent)\n",
    "            files = os.listdir(path)\n",
    "            print len(files), path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ae566e4bc10>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ae564d5aa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from constant import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f = open(caffe_root + 'data/ilsvrc12/synset_words.txt')\n",
    "label_to_wnid = f.readlines()\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "folders = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/')\n",
    "count = []\n",
    "for folder in folders:\n",
    "    image_names = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/' + folder)\n",
    "    annotation_names = os.listdir(imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/' + folder)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    count.append(len(intersection_names))\n",
    "\n",
    "x = [i for i in range(len(count))]\n",
    "count = sorted(count)\n",
    "plt.plot(x, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "print count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
