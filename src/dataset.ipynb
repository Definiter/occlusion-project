{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%file dataset.py\n",
    "# Generate training dataset and test dataset.\n",
    "from constant import *\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "#### Parameters. ####\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_index', required=True)\n",
    "parser.add_argument('--type_str', required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "#type_str = 'nocrop' # {1k_}[crop | nocrop | crop_obj | nocrop_obj | aperture]\n",
    "type_str = args.type_str\n",
    "\n",
    "#dataset = [(0.0, 0), (1.0/4, 4), (1.0/3, 3), (1.0/2, 3), (2.0/3, 3), (4.0/5, 3), (9.0/10, 3), (1.0, 1)]\n",
    "#dataset = [(0.0, 0), (0.1, 10), (0.2, 5), (0.3, 4), (0.4, 3), (0.5, 3), (0.6, 3), (0.7, 3), (0.8, 3), (0.9, 3), (1.0, 1)]\n",
    "#dataset = [(0.0, 0), (0.2, 9), (0.4, 9), (0.6, 9), (0.8, 9), (1.0, 9)] # when crop_obj or nocrop_obj, (size, total_num)\n",
    "dataset = [(0.0, 0),  (0.1, 10), (0.2, 10), (0.3, 10), (0.4, 10),\\\n",
    "           (0.5, 10), (0.6, 10), (0.7, 10), (0.8, 10), (0.9, 10), (1.0, 1)]\n",
    "dataset_index = int(args.dataset_index)\n",
    "#dataset_index = 5\n",
    "print 'Processsing dataset {}, type_str {}'.format(dataset[dataset_index], type_str)\n",
    "dataset = [dataset[dataset_index]]\n",
    "\n",
    "# divide to training dataset and test dataset\n",
    "training_dataset_size = 300\n",
    "validation_dataset_size = 100\n",
    "test_dataset_size = 100\n",
    "\n",
    "# obj image: always 1024 * 768 pixels\n",
    "obj_width = 1024\n",
    "obj_height = 768\n",
    "obj_ratio = float(obj_width) / obj_height\n",
    "#####################\n",
    "\n",
    "mean_color = (123, 117, 104)\n",
    "\n",
    "# Load labels.\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "label_to_wnid = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "train_folders = []\n",
    "val_folders = []\n",
    "test_folders = []\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/train_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    train_files.append(f)\n",
    "    \n",
    "    folder = '{}dataset/train_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    train_folders.append(folder)\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/val_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    val_files.append(f)\n",
    "\n",
    "    folder = '{}dataset/val_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    val_folders.append(folder)\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/test_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    test_files.append(f)\n",
    "\n",
    "    folder = '{}dataset/test_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    test_folders.append(folder)\n",
    "    \n",
    "if 'obj' in type_str:\n",
    "    obj_images = []\n",
    "    for i, image_name in enumerate(os.listdir(shapenet_root + 'object_nobg/')):\n",
    "        img_temp = Image.open(shapenet_root + 'object_nobg/' + image_name)\n",
    "        img = img_temp.copy()\n",
    "        img_temp.close()\n",
    "        #img = img.convert(\"RGBA\")\n",
    "        obj_images.append(img)\n",
    "    print \"{} object occluders loaded.\".format(len(obj_images))\n",
    "\n",
    "# occluder size = slider_size * slider_size\n",
    "# occluder num = slider_num * slider_num\n",
    "# path = 'imagenet_root/dataset/train_0/name'\n",
    "# {wnid_imgid}_{crop/nocrop}_{rect_i(ifcrop)}_{slider_size}_{i}_{j}\n",
    "def generate_datum(img_orig, path, f, class_id, rects, slider_size, slider_num):\n",
    "    if type_str == 'crop' or type_str == '1k_crop':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "                    d.rectangle(subrect, fill=mean_color, outline=None)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "    if type_str == 'nocrop' or type_str == '1k_nocrop':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_0_0_0.jpeg'.format(path, type_str)\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for i in range(slider_num):\n",
    "                img = img_orig.copy()\n",
    "                d = ImageDraw.Draw(img)\n",
    "                for rect in rects:\n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "                    d.rectangle(subrect, fill=mean_color, outline=None)\n",
    "                datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, 0, str(int(100 * slider_size)), i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))                    \n",
    "    \n",
    "    if type_str == 'crop_obj' or type_str == '1k_crop_obj':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, int(100 * slider_size))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for num in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    random_obj = obj_images[random.randint(0, len(obj_images) - 1)].copy()\n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    if ratio >= obj_ratio:\n",
    "                        resize_scale = float(height) / obj_height * slider_size\n",
    "                    else:\n",
    "                        resize_scale = float(width) / obj_width * slider_size\n",
    "                    new_width = int(obj_width * resize_scale)\n",
    "                    new_height = int(obj_height * resize_scale)\n",
    "                    if new_width == 0:\n",
    "                        new_width = 1\n",
    "                    if new_height == 0:\n",
    "                        new_height = 1\n",
    "                    random_obj = random_obj.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "                    \n",
    "                    rangex = [rect[0], rect[2] - random_obj.size[0]]\n",
    "                    if rangex[1] < rangex[0]:\n",
    "                        rangex[1] = rangex[0]\n",
    "                        \n",
    "                    rangey = [rect[1], rect[3] - random_obj.size[1]]\n",
    "                    if rangey[1] < rangey[0]:\n",
    "                        rangey[1] = rangey[0]\n",
    "                    top_left = (random.randint(rangex[0], rangex[1]), random.randint(rangey[0], rangey[1]))\n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "                    \n",
    "    if type_str == 'nocrop_obj' or type_str == '1k_nocrop_obj':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, 0, int(100 * slider_size))\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for num in range(slider_num):\n",
    "                img = img_orig.copy()\n",
    "                for rect_i, rect in enumerate(rects):\n",
    "                    random_obj = obj_images[random.randint(0, len(obj_images) - 1)].copy()\n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    if ratio >= obj_ratio:\n",
    "                        resize_scale = float(height) / obj_height * slider_size\n",
    "                    else:\n",
    "                        resize_scale = float(width) / obj_width * slider_size\n",
    "                    new_width = int(obj_width * resize_scale)\n",
    "                    new_height = int(obj_height * resize_scale)\n",
    "                    if new_width == 0:\n",
    "                        new_width = 1\n",
    "                    if new_height == 0:\n",
    "                        new_height = 1\n",
    "                    random_obj = random_obj.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "                    \n",
    "                    rangex = [rect[0], rect[2] - random_obj.size[0]]\n",
    "                    if rangex[1] < rangex[0]:\n",
    "                        rangex[1] = rangex[0]\n",
    "                        \n",
    "                    rangey = [rect[1], rect[3] - random_obj.size[1]]\n",
    "                    if rangey[1] < rangey[0]:\n",
    "                        rangey[1] = rangey[0]\n",
    "                    top_left = (random.randint(rangex[0], rangex[1]), random.randint(rangey[0], rangey[1]))\n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    \n",
    "                datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))              \n",
    "                    \n",
    "                    \n",
    "    if type_str == 'aperture' or type_str == '1k_aperture':\n",
    "        if slider_size == 0: # All black.\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                d = ImageDraw.Draw(img)\n",
    "                d.rectangle(rect, fill=\"black\", outline=None)\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        elif slider_size == 1: # All visible. \n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    for j in range(slider_num):\n",
    "                        img = img_orig.copy()\n",
    "                        d = ImageDraw.Draw(img)\n",
    "                        delta = (1 - slider_size) / float(slider_num - 1)\n",
    "                        subrect = [0, 0, 0, 0]\n",
    "                        subrect[0] = rect[0] + i * (rect[2] - rect[0]) * delta\n",
    "                        subrect[1] = rect[1] + j * (rect[3] - rect[1]) * delta\n",
    "                        subrect[2] = subrect[0] + (rect[2] - rect[0]) * slider_size\n",
    "                        subrect[3] = subrect[1] + (rect[3] - rect[1]) * slider_size\n",
    "                        d.rectangle([0, 0, img.size[0], subrect[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([0, 0, subrect[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([subrect[2], 0, img.size[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([0, subrect[3], img.size[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        img = img.crop(rect)\n",
    "                        datum_path = '{}_{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), str(i), str(j))\n",
    "                        img.save(datum_path)\n",
    "                        f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "            \n",
    "image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "annotation_path =  imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/'\n",
    "\n",
    "if '1k' in type_str:\n",
    "    synset_names = os.listdir(image_path)\n",
    "            \n",
    "start_time = time.time()\n",
    "\n",
    "dataset_sum = training_dataset_size + validation_dataset_size + test_dataset_size\n",
    "all_sum = len(synset_names) * dataset_sum\n",
    "print all_sum\n",
    "\n",
    "for synset_index, synset_name in enumerate(synset_names):\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    annotation_names = os.listdir(annotation_path + synset_name)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    for i in range(dataset_sum):\n",
    "        if (i + 1) % 50 == 0:\n",
    "            second = int(time.time() - start_time)\n",
    "            now_time = time.strftime(\"%H:%M:%S\", time.gmtime(second))\n",
    "            now_sum = synset_index * dataset_sum + i\n",
    "            \n",
    "            estimated = int(float(all_sum) / now_sum * second)\n",
    "            estimated_time = time.strftime(\"%H:%M:%S\", time.gmtime(estimated))\n",
    "            estimated_day = estimated / 3600 / 24\n",
    "            print '[{}/{} {}]Processing synset [{}/{}], image [{}/{}]: {}'.format(now_time, estimated_day, estimated_time, synset_index + 1, len(synset_names), i + 1, dataset_sum, intersection_names[i])\n",
    "        # Read bounding box.\n",
    "        bbx_file = open(annotation_path + synset_name + '/' + intersection_names[i] + '.xml')\n",
    "        xmltree = ET.parse(bbx_file)\n",
    "        objects = xmltree.findall('object')\n",
    "        rects = []\n",
    "        for obj in objects:\n",
    "            bbx = obj.find('bndbox')\n",
    "            rects.append([int(it.text) for it in bbx])\n",
    "            \n",
    "        img_orig = Image.open(image_path + synset_name + '/' + intersection_names[i] + '.JPEG')\n",
    "        if img_orig.mode != \"RGB\":\n",
    "            img_orig = img_orig.convert(\"RGB\")\n",
    "            \n",
    "        if '1k' in type_str:\n",
    "            class_id = wnid_to_label[synset_name]\n",
    "        else:\n",
    "            class_id = original_to_new_class_id[wnid_to_label[synset_name]]\n",
    "        \n",
    "        if i < training_dataset_size: # Training dataset. \n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(train_folders[index], intersection_names[i]), \\\n",
    "                               train_files[index], class_id, rects, slider_size, slider_num)\n",
    "        elif i < training_dataset_size + validation_dataset_size: # Validation dataset\n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(val_folders[index], intersection_names[i]), \\\n",
    "                               val_files[index], class_id, rects, slider_size, slider_num)\n",
    "        else: # Test dataset.\n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(test_folders[index], intersection_names[i]), \\\n",
    "                               test_files[index], class_id, rects, slider_size, slider_num)\n",
    "                               \n",
    "for f in train_files:\n",
    "    f.close()\n",
    "for f in test_files:\n",
    "    f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample or for lmdb.\n",
    "\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "import shutil\n",
    "\n",
    "mode = 'nosample'\n",
    "is_lmdb = True\n",
    "\n",
    "func_strs = ['train', 'val', 'test']\n",
    "type_strs = ['crop', 'nocrop']\n",
    "names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100']\n",
    "sample_sum = {'train': 100000, 'test': 50000}\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        for name in names:\n",
    "            #shutil.copyfile('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), \\\n",
    "            #         '{}dataset/{}_{}_{}_unsampled.txt'.format(imagenet_root, func_str, type_str, name))\n",
    "            with open('{}dataset/{}_{}_{}_unsampled.txt'.format(imagenet_root, func_str, type_str, name)) as f:\n",
    "                lines = f.readlines()\n",
    "            if mode == 'nosample':\n",
    "                sampled = lines\n",
    "            else:\n",
    "                sampled = random.sample(lines, sample_sum[func_str])\n",
    "            if is_lmdb:\n",
    "                for i in range(len(sampled)):\n",
    "                    sampled[i] = sampled[i].split('/')[-2] + '/' + sampled[i].split('/')[-1]\n",
    "            with open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), 'w') as f:\n",
    "                f.writelines(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create {}_{}_all.txt.\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "\n",
    "type_strs = ['crop', 'nocrop']\n",
    "func_strs = ['train', 'val', 'test']\n",
    "#names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100']\n",
    "names = ['0', '20', '40', '60', '80', '100']\n",
    "sample_sum = {'train': {'crop': 343360, 'nocrop': 300000}, \\\n",
    "              'val': {'crop': 114010, 'nocrop': 100000}, \\\n",
    "              'test': {'crop': 114060, 'nocrop': 100000}}\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        lines = []\n",
    "        for name in names:\n",
    "            f = open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), 'r')\n",
    "            ls = f.readlines()\n",
    "            f.close()\n",
    "            lines = lines + ls\n",
    "        f = open('{}dataset/{}_{}_all_unsampled.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        sampled = random.sample(lines, sample_sum[func_str][type_str])\n",
    "        f = open('{}dataset/{}_{}_all.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(sampled)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%file transparent.py\n",
    "# Make white color transparent.\n",
    "from constant import *\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_names = os.listdir(shapenet_root + 'object_orig/')\n",
    "print len(image_names)\n",
    "\n",
    "for i, image_name in enumerate(image_names):\n",
    "    print '[{}/{}]: {}'.format(i, len(image_names), image_name)\n",
    "    img = Image.open(shapenet_root + 'object_orig/' + image_name)\n",
    "    \n",
    "    img = img.convert(\"RGBA\")\n",
    "    pixdata = img.load()\n",
    "    for y in xrange(img.size[1]):\n",
    "        for x in xrange(img.size[0]):\n",
    "            if pixdata[x, y] == (255, 255, 255, 255):\n",
    "                pixdata[x, y] = (255, 255, 255, 0)\n",
    "    img.save(shapenet_root + 'object_nobg/' + image_name, 'PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sewing machine http://image-net.org/synset?wnid=n04179913\n",
      "parking meter http://image-net.org/synset?wnid=n03891332\n",
      "hard disc, hard disk, fixed disk http://image-net.org/synset?wnid=n03492542\n",
      "hyena, hyaena http://image-net.org/synset?wnid=n02117135\n",
      "three-toed sloth, ai, Bradypus tridactylus http://image-net.org/synset?wnid=n02457408\n",
      "fur coat http://image-net.org/synset?wnid=n03404251\n",
      "Arctic fox, white fox, Alopex lagopus http://image-net.org/synset?wnid=n02120079\n",
      "great grey owl, great gray owl, Strix nebulosa http://image-net.org/synset?wnid=n01622779\n",
      "scoreboard http://image-net.org/synset?wnid=n04149813\n",
      "cinema, movie theater, movie theatre, movie house, picture palace http://image-net.org/synset?wnid=n03032252\n",
      "tusker http://image-net.org/synset?wnid=n01871265\n",
      "window screen http://image-net.org/synset?wnid=n04589890\n",
      "sock http://image-net.org/synset?wnid=n04254777\n",
      "tiger, Panthera tigris http://image-net.org/synset?wnid=n02129604\n",
      "saltshaker, salt shaker http://image-net.org/synset?wnid=n04131690\n",
      "boxer http://image-net.org/synset?wnid=n02108089\n",
      "banana http://image-net.org/synset?wnid=n07753592\n",
      "loupe, jeweler's loupe http://image-net.org/synset?wnid=n03692522\n",
      "volleyball http://image-net.org/synset?wnid=n04540053\n",
      "bow tie, bow-tie, bowtie http://image-net.org/synset?wnid=n02883205\n",
      "hook, claw http://image-net.org/synset?wnid=n03532672\n",
      "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens http://image-net.org/synset?wnid=n02509815\n",
      "electric fan, blower http://image-net.org/synset?wnid=n03271574\n",
      "alp http://image-net.org/synset?wnid=n09193705\n",
      "miniskirt, mini http://image-net.org/synset?wnid=n03770439\n",
      "white stork, Ciconia ciconia http://image-net.org/synset?wnid=n02002556\n",
      "Pekinese, Pekingese, Peke http://image-net.org/synset?wnid=n02086079\n",
      "rule, ruler http://image-net.org/synset?wnid=n04118776\n",
      "ski mask http://image-net.org/synset?wnid=n04229816\n",
      "long-horned beetle, longicorn, longicorn beetle http://image-net.org/synset?wnid=n02168699\n",
      "triumphal arch http://image-net.org/synset?wnid=n04486054\n",
      "mink http://image-net.org/synset?wnid=n02442845\n",
      "koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus http://image-net.org/synset?wnid=n01882714\n",
      "yawl http://image-net.org/synset?wnid=n04612504\n",
      "mobile home, manufactured home http://image-net.org/synset?wnid=n03776460\n",
      "sea cucumber, holothurian http://image-net.org/synset?wnid=n02321529\n",
      "poncho http://image-net.org/synset?wnid=n03980874\n",
      "rain barrel http://image-net.org/synset?wnid=n04049303\n",
      "shower cap http://image-net.org/synset?wnid=n04209133\n",
      "green snake, grass snake http://image-net.org/synset?wnid=n01729977\n",
      "dough http://image-net.org/synset?wnid=n07860988\n",
      "seat belt, seatbelt http://image-net.org/synset?wnid=n04162706\n",
      "golden retriever http://image-net.org/synset?wnid=n02099601\n",
      "amphibian, amphibious vehicle http://image-net.org/synset?wnid=n02704792\n",
      "washbasin, handbasin, washbowl, lavabo, wash-hand basin http://image-net.org/synset?wnid=n04553703\n",
      "hummingbird http://image-net.org/synset?wnid=n01833805\n",
      "abacus http://image-net.org/synset?wnid=n02666196\n",
      "flute, transverse flute http://image-net.org/synset?wnid=n03372029\n",
      "yurt http://image-net.org/synset?wnid=n04613696\n",
      "Indian elephant, Elephas maximus http://image-net.org/synset?wnid=n02504013\n",
      "sunscreen, sunblock, sun blocker http://image-net.org/synset?wnid=n04357314\n",
      "hotdog, hot dog, red hot http://image-net.org/synset?wnid=n07697537\n",
      "German shepherd, German shepherd dog, German police dog, alsatian http://image-net.org/synset?wnid=n02106662\n",
      "baboon http://image-net.org/synset?wnid=n02486410\n",
      "Pomeranian http://image-net.org/synset?wnid=n02112018\n",
      "sunglasses, dark glasses, shades http://image-net.org/synset?wnid=n04356056\n",
      "crane http://image-net.org/synset?wnid=n02012849\n",
      "Siamese cat, Siamese http://image-net.org/synset?wnid=n02123597\n",
      "sax, saxophone http://image-net.org/synset?wnid=n04141076\n",
      "polecat, fitch, foulmart, foumart, Mustela putorius http://image-net.org/synset?wnid=n02443114\n",
      "mortarboard http://image-net.org/synset?wnid=n03787032\n",
      "jackfruit, jak, jack http://image-net.org/synset?wnid=n07754684\n",
      "holster http://image-net.org/synset?wnid=n03527444\n",
      "balance beam, beam http://image-net.org/synset?wnid=n02777292\n",
      "squirrel monkey, Saimiri sciureus http://image-net.org/synset?wnid=n02494079\n",
      "Chihuahua http://image-net.org/synset?wnid=n02085620\n",
      "artichoke, globe artichoke http://image-net.org/synset?wnid=n07718747\n",
      "padlock http://image-net.org/synset?wnid=n03874599\n",
      "American chameleon, anole, Anolis carolinensis http://image-net.org/synset?wnid=n01682714\n",
      "goldfish, Carassius auratus http://image-net.org/synset?wnid=n01443537\n",
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca http://image-net.org/synset?wnid=n02510455\n",
      "odometer, hodometer, mileometer, milometer http://image-net.org/synset?wnid=n03841143\n",
      "howler monkey, howler http://image-net.org/synset?wnid=n02492660\n",
      "church, church building http://image-net.org/synset?wnid=n03028079\n",
      "agama http://image-net.org/synset?wnid=n01687978\n",
      "conch http://image-net.org/synset?wnid=n01943899\n",
      "mongoose http://image-net.org/synset?wnid=n02137549\n",
      "oboe, hautboy, hautbois http://image-net.org/synset?wnid=n03838899\n",
      "microphone, mike http://image-net.org/synset?wnid=n03759954\n",
      "cassette http://image-net.org/synset?wnid=n02978881\n",
      "traffic light, traffic signal, stoplight http://image-net.org/synset?wnid=n06874185\n",
      "oystercatcher, oyster catcher http://image-net.org/synset?wnid=n02037110\n",
      "gibbon, Hylobates lar http://image-net.org/synset?wnid=n02483362\n",
      "running shoe http://image-net.org/synset?wnid=n04120489\n",
      "bikini, two-piece http://image-net.org/synset?wnid=n02837789\n",
      "Eskimo dog, husky http://image-net.org/synset?wnid=n02109961\n",
      "Arabian camel, dromedary, Camelus dromedarius http://image-net.org/synset?wnid=n02437312\n",
      "dial telephone, dial phone http://image-net.org/synset?wnid=n03187595\n",
      "Norfolk terrier http://image-net.org/synset?wnid=n02094114\n",
      "porcupine, hedgehog http://image-net.org/synset?wnid=n02346627\n",
      "croquet ball http://image-net.org/synset?wnid=n03134739\n",
      "Norwich terrier http://image-net.org/synset?wnid=n02094258\n",
      "oxcart http://image-net.org/synset?wnid=n03868242\n",
      "cabbage butterfly http://image-net.org/synset?wnid=n02280649\n",
      "apron http://image-net.org/synset?wnid=n02730930\n",
      "lifeboat http://image-net.org/synset?wnid=n03662601\n",
      "meat loaf, meatloaf http://image-net.org/synset?wnid=n07871810\n",
      "bottlecap http://image-net.org/synset?wnid=n02877765\n",
      "Model T http://image-net.org/synset?wnid=n03777568\n",
      "ground beetle, carabid beetle http://image-net.org/synset?wnid=n02167151\n"
     ]
    }
   ],
   "source": [
    "# Show typical images of each class.\n",
    "from constant import *\n",
    "import os\n",
    "import numpy as np\n",
    "#from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "with open(imagenet_labels_filename) as f:\n",
    "    lines = f.readlines()\n",
    "wnid_to_name = {}\n",
    "for line in lines:\n",
    "    wnid = line.split(' ')[0]\n",
    "    name = line[(len(wnid) + 1):-1]\n",
    "    wnid_to_name[wnid] = name\n",
    "\n",
    "image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "for synset_name in synset_names:\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    print wnid_to_name[synset_name], 'http://image-net.org/synset?wnid=' + synset_name\n",
    "    #display(Image(filename=image_path + synset_name + '/' + image_names[0]))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     30000 /data2/haow3/data/imagenet/dataset/train_nocrop_0.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_10.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_20.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_30.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_40.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_50.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_60.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_70.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_80.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_90.txt\n",
      "     30000 /data2/haow3/data/imagenet/dataset/train_nocrop_100.txt\n",
      "    300000 /data2/haow3/data/imagenet/dataset/train_nocrop_all.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_0.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_10.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_20.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_30.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_40.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_50.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_60.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_70.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_80.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_90.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_100.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_all.txt\n",
      "     10000 /data2/haow3/data/imagenet/dataset/val_nocrop_0.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_10.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_20.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_30.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_40.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_50.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_60.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_70.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_80.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_90.txt\n",
      "     10000 /data2/haow3/data/imagenet/dataset/val_nocrop_100.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/val_nocrop_all.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_0.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_10.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_20.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_30.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_40.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_50.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_60.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_70.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_80.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_90.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_100.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_all.txt\n",
      "     10000 /data2/haow3/data/imagenet/dataset/test_nocrop_0.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_10.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_20.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_30.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_40.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_50.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_60.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_70.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_80.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_90.txt\n",
      "     10000 /data2/haow3/data/imagenet/dataset/test_nocrop_100.txt\n",
      "    100000 /data2/haow3/data/imagenet/dataset/test_nocrop_all.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_0.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_10.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_20.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_30.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_40.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_50.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_60.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_70.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_80.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_90.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_100.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_all.txt\n"
     ]
    }
   ],
   "source": [
    "# Sanity check.\n",
    "import os\n",
    "from constant import *\n",
    "\n",
    "func_strs = ['train', 'val', 'test']\n",
    "type_strs = ['nocrop', 'crop']\n",
    "names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100', 'all']\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        for name in names:\n",
    "            filename = '{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name) \n",
    "            f = open(filename)\n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            print '{:10d} {}'.format(len(lines), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from constant import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f = open(caffe_root + 'data/ilsvrc12/synset_words.txt')\n",
    "label_to_wnid = f.readlines()\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "folders = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/')\n",
    "count = []\n",
    "for folder in folders:\n",
    "    image_names = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/' + folder)\n",
    "    annotation_names = os.listdir(imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/' + folder)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    count.append(len(intersection_names))\n",
    "\n",
    "x = [i for i in range(len(count))]\n",
    "count = sorted(count)\n",
    "plt.plot(x, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n04179913', 'n03891332', 'n03492542', 'n02117135', 'n02457408', 'n03404251', 'n02120079', 'n01622779', 'n04149813', 'n03032252', 'n01871265', 'n04589890', 'n04254777', 'n02129604', 'n04131690', 'n02108089', 'n07753592', 'n03692522', 'n04540053', 'n02883205', 'n03532672', 'n02509815', 'n03271574', 'n09193705', 'n03770439', 'n02002556', 'n02086079', 'n04118776', 'n04229816', 'n02168699', 'n04486054', 'n02442845', 'n01882714', 'n04612504', 'n03776460', 'n02321529', 'n03980874', 'n04049303', 'n04209133', 'n01729977', 'n07860988', 'n04162706', 'n02099601', 'n02704792', 'n04553703', 'n01833805', 'n02666196', 'n03372029', 'n04613696', 'n02504013', 'n04357314', 'n07697537', 'n02106662', 'n02486410', 'n02112018', 'n04356056', 'n02012849', 'n02123597', 'n04141076', 'n02443114', 'n03787032', 'n07754684', 'n03527444', 'n02777292', 'n02494079', 'n02085620', 'n07718747', 'n03874599', 'n01682714', 'n01443537', 'n02510455', 'n03841143', 'n02492660', 'n03028079', 'n01687978', 'n01943899', 'n02137549', 'n03838899', 'n03759954', 'n02978881', 'n06874185', 'n02037110', 'n02483362', 'n04120489', 'n02837789', 'n02109961', 'n02437312', 'n03187595', 'n02094114', 'n02346627', 'n03134739', 'n02094258', 'n03868242', 'n02280649', 'n02730930', 'n03662601', 'n07871810', 'n02877765', 'n03777568', 'n02167151']\n",
      "[1, 24, 40, 42, 55, 94, 101, 105, 112, 127, 134, 143, 151, 154, 185, 186, 207, 235, 242, 248, 259, 276, 279, 284, 292, 298, 302, 303, 324, 329, 334, 354, 357, 358, 364, 368, 372, 379, 382, 385, 387, 388, 398, 408, 411, 416, 445, 455, 457, 481, 497, 498, 522, 528, 545, 558, 568, 592, 597, 600, 625, 633, 650, 655, 660, 661, 667, 683, 685, 690, 695, 704, 735, 756, 769, 770, 773, 776, 781, 785, 786, 793, 796, 806, 837, 838, 873, 890, 896, 904, 914, 915, 920, 934, 944, 954, 955, 961, 962, 970]\n",
      "{1: 0, 522: 52, 528: 53, 24: 1, 545: 54, 40: 2, 42: 3, 558: 55, 55: 4, 568: 56, 592: 57, 597: 58, 600: 59, 94: 5, 101: 6, 105: 7, 112: 8, 625: 60, 633: 61, 127: 9, 134: 10, 650: 62, 143: 11, 660: 64, 661: 65, 151: 12, 154: 13, 667: 66, 796: 82, 683: 67, 685: 68, 690: 69, 695: 70, 185: 14, 186: 15, 704: 71, 207: 16, 735: 72, 235: 17, 242: 18, 756: 73, 248: 19, 769: 74, 770: 75, 259: 20, 773: 76, 776: 77, 781: 78, 785: 79, 786: 80, 276: 21, 279: 22, 793: 81, 284: 23, 292: 24, 806: 83, 298: 25, 302: 26, 303: 27, 324: 28, 837: 84, 838: 85, 329: 29, 334: 30, 655: 63, 354: 31, 357: 32, 358: 33, 873: 86, 364: 34, 368: 35, 372: 36, 890: 87, 379: 37, 382: 38, 896: 88, 385: 39, 387: 40, 388: 41, 904: 89, 398: 42, 920: 92, 914: 90, 915: 91, 408: 43, 411: 44, 416: 45, 934: 93, 944: 94, 954: 95, 955: 96, 445: 46, 961: 97, 962: 98, 455: 47, 457: 48, 970: 99, 481: 49, 497: 50, 498: 51}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ab6709eba10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly sample classes for experiment.\n",
    "import os\n",
    "from constant import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "label_to_wnid = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "\n",
    "synset_name_to_original_id = {}\n",
    "for original_id in range(len(label_to_wnid)):\n",
    "    synset_name = label_to_wnid[original_id].split(' ')[0]\n",
    "    synset_name_to_original_id[synset_name] = original_id\n",
    "\n",
    "image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "annotation_path =  imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/'\n",
    "\n",
    "count = []\n",
    "sampled = []\n",
    "for synset_index, synset_name in enumerate(os.listdir(image_path)):\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    annotation_names = os.listdir(annotation_path + synset_name)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    count.append(len(intersection_names))\n",
    "    if len(intersection_names) >= 500:\n",
    "        sampled.append(synset_name)\n",
    "\n",
    "count = sorted(count)\n",
    "plt.plot(count)\n",
    "\n",
    "sampled = random.sample(sampled, 100)\n",
    "print sampled\n",
    "\n",
    "new_to_original_class_id = []\n",
    "original_to_new_class_id = {}\n",
    "for synset_name in sampled:\n",
    "    new_to_original_class_id.append(synset_name_to_original_id[synset_name])\n",
    "new_to_original_class_id = sorted(new_to_original_class_id)\n",
    "print new_to_original_class_id\n",
    "\n",
    "for i, original_id in enumerate(new_to_original_class_id):\n",
    "    original_to_new_class_id[original_id] = i\n",
    "print original_to_new_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goldfish, Carassius auratus\n",
      "great grey owl, great gray owl, Strix nebulosa\n",
      "American chameleon, anole, Anolis carolinensis\n",
      "agama\n",
      "green snake, grass snake\n",
      "hummingbird\n",
      "tusker\n",
      "koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\n",
      "conch\n",
      "white stork, Ciconia ciconia\n",
      "crane\n",
      "oystercatcher, oyster catcher\n",
      "Chihuahua\n",
      "Pekinese, Pekingese, Peke\n",
      "Norfolk terrier\n",
      "Norwich terrier\n",
      "golden retriever\n",
      "German shepherd, German shepherd dog, German police dog, alsatian\n",
      "boxer\n",
      "Eskimo dog, husky\n",
      "Pomeranian\n",
      "hyena, hyaena\n",
      "Arctic fox, white fox, Alopex lagopus\n",
      "Siamese cat, Siamese\n",
      "tiger, Panthera tigris\n",
      "mongoose\n",
      "ground beetle, carabid beetle\n",
      "long-horned beetle, longicorn, longicorn beetle\n",
      "cabbage butterfly\n",
      "sea cucumber, holothurian\n",
      "porcupine, hedgehog\n",
      "Arabian camel, dromedary, Camelus dromedarius\n",
      "mink\n",
      "polecat, fitch, foulmart, foumart, Mustela putorius\n",
      "three-toed sloth, ai, Bradypus tridactylus\n",
      "gibbon, Hylobates lar\n",
      "baboon\n",
      "howler monkey, howler\n",
      "squirrel monkey, Saimiri sciureus\n",
      "Indian elephant, Elephas maximus\n",
      "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\n",
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\n",
      "abacus\n",
      "amphibian, amphibious vehicle\n",
      "apron\n",
      "balance beam, beam\n",
      "bikini, two-piece\n",
      "bottlecap\n",
      "bow tie, bow-tie, bowtie\n",
      "cassette\n",
      "church, church building\n",
      "cinema, movie theater, movie theatre, movie house, picture palace\n",
      "croquet ball\n",
      "dial telephone, dial phone\n",
      "electric fan, blower\n",
      "flute, transverse flute\n",
      "fur coat\n",
      "hard disc, hard disk, fixed disk\n",
      "holster\n",
      "hook, claw\n",
      "lifeboat\n",
      "loupe, jeweler's loupe\n",
      "microphone, mike\n",
      "miniskirt, mini\n",
      "mobile home, manufactured home\n",
      "Model T\n",
      "mortarboard\n",
      "oboe, hautboy, hautbois\n",
      "odometer, hodometer, mileometer, milometer\n",
      "oxcart\n",
      "padlock\n",
      "parking meter\n",
      "poncho\n",
      "rain barrel\n",
      "rule, ruler\n",
      "running shoe\n",
      "saltshaker, salt shaker\n",
      "sax, saxophone\n",
      "scoreboard\n",
      "seat belt, seatbelt\n",
      "sewing machine\n",
      "shower cap\n",
      "ski mask\n",
      "sock\n",
      "sunglasses, dark glasses, shades\n",
      "sunscreen, sunblock, sun blocker\n",
      "triumphal arch\n",
      "volleyball\n",
      "washbasin, handbasin, washbowl, lavabo, wash-hand basin\n",
      "window screen\n",
      "yawl\n",
      "yurt\n",
      "traffic light, traffic signal, stoplight\n",
      "hotdog, hot dog, red hot\n",
      "artichoke, globe artichoke\n",
      "banana\n",
      "jackfruit, jak, jack\n",
      "dough\n",
      "meat loaf, meatloaf\n",
      "alp\n"
     ]
    }
   ],
   "source": [
    "# Generate label list.\n",
    "import os\n",
    "from constant import *\n",
    "\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "lines = open(imagenet_labels_filename).readlines()\n",
    "\n",
    "original_id_to_name = []\n",
    "for line in lines:\n",
    "    wnid = line.split(' ')[0]\n",
    "    name = line[(len(wnid) + 1):-1]\n",
    "    original_id_to_name.append(name)\n",
    "    \n",
    "    \n",
    "label = [None for i in range(len(synset_names))]\n",
    "\n",
    "for new_id, original_id in enumerate(new_to_original_class_id):\n",
    "    label[new_id] = original_id_to_name[original_id]\n",
    "    print label[new_id]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
