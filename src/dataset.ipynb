{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%file dataset.py\n",
    "# Generate training dataset and test dataset.\n",
    "from constant import *\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "#### Parameters. ####\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_index', required=True)\n",
    "parser.add_argument('--type_str', required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "#type_str = '1k_nocrop_obj' # {1k_}[crop | nocrop | crop_obj | nocrop_obj | aperture]\n",
    "type_str = args.type_str\n",
    "\n",
    "#dataset = [(0.0, 0), (1.0/4, 4), (1.0/3, 3), (1.0/2, 3), (2.0/3, 3), (4.0/5, 3), (9.0/10, 3), (1.0, 1)]\n",
    "#dataset = [(0.0, 0), (0.1, 10), (0.2, 5), (0.3, 4), (0.4, 3), (0.5, 3), (0.6, 3), (0.7, 3), (0.8, 3), (0.9, 3), (1.0, 1)]\n",
    "dataset = [(0.0, 0), (0.2, 9), (0.4, 9), (0.6, 9), (0.8, 9), (1.0, 9)] # when crop_obj or nocrop_obj, (size, total_num)\n",
    "dataset = [dataset[int(args.dataset_index)]]\n",
    "print 'Processsing dataset {}, type_str {}'.format(dataset[0], type_str)\n",
    "\n",
    "# divide to training dataset and test dataset\n",
    "training_dataset_size = 100\n",
    "test_dataset_size = 50\n",
    "\n",
    "# obj image: always 1024 * 768 pixels\n",
    "obj_width = 1024\n",
    "obj_height = 768\n",
    "obj_ratio = float(obj_width) / obj_height\n",
    "#####################\n",
    "\n",
    "# Load labels.\n",
    "imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "label_to_wnid = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "training_dataset = dataset\n",
    "test_dataset = dataset\n",
    "\n",
    "train_folders = []\n",
    "test_folders = []\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "for (slider_size, slider_num) in training_dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/train_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    train_files.append(f)\n",
    "    \n",
    "    folder = '{}dataset/train_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    train_folders.append(folder)\n",
    "        \n",
    "\n",
    "for (slider_size, slider_num) in test_dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/test_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    test_files.append(f)\n",
    "\n",
    "    folder = '{}dataset/test_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    test_folders.append(folder)\n",
    "    \n",
    "if 'obj' in type_str:\n",
    "    obj_images = []\n",
    "    for i, image_name in enumerate(os.listdir(shapenet_root + 'object_nobg/')):\n",
    "        img_temp = Image.open(shapenet_root + 'object_nobg/' + image_name)\n",
    "        img = img_temp.copy()\n",
    "        img_temp.close()\n",
    "        #img = img.convert(\"RGBA\")\n",
    "        obj_images.append(img)\n",
    "print \"{} object occluders loaded.\".format(len(obj_images))\n",
    "\n",
    "# occluder size = slider_size * slider_size\n",
    "# occluder num = slider_num * slider_num\n",
    "# path = 'imagenet_root/dataset/train_0/name'\n",
    "# {wnid_imgid}_{crop/nocrop}_{rect_i(ifcrop)}_{slider_size}_{i}_{j}\n",
    "def generate_datum(img_orig, path, f, class_id, rects, slider_size, slider_num):\n",
    "    if type_str == 'crop' or type_str == '1k_crop':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_0_0_0.jpeg'.format(path, type_str, rect_i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    for j in range(slider_num):\n",
    "                        img = img_orig.copy()\n",
    "                        d = ImageDraw.Draw(img)\n",
    "                        if (slider_num == 1):\n",
    "                            delta = 1\n",
    "                        else:\n",
    "                            delta = (1 - slider_size) / float(slider_num - 1)\n",
    "                        subrect = [0, 0, 0, 0]\n",
    "                        subrect[0] = rect[0] + i * (rect[2] - rect[0]) * delta\n",
    "                        subrect[1] = rect[1] + j * (rect[3] - rect[1]) * delta\n",
    "                        subrect[2] = subrect[0] + (rect[2] - rect[0]) * slider_size\n",
    "                        subrect[3] = subrect[1] + (rect[3] - rect[1]) * slider_size\n",
    "                        d.rectangle(subrect, fill=\"black\", outline=None)\n",
    "                        img = img.crop(rect)\n",
    "                        datum_path = '{}_{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), str(i), str(j))\n",
    "                        img.save(datum_path)\n",
    "                        f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "    if type_str == 'nocrop' or type_str == '1k_nocrop':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_0_0_0_0.jpeg'.format(path, type_str)\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for i in range(slider_num):\n",
    "                for j in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    if (slider_num == 1):\n",
    "                        delta = 1\n",
    "                    else:\n",
    "                        delta = (1 - slider_size) / float(slider_num - 1)\n",
    "                    for rect in rects:\n",
    "                        subrect = [0, 0, 0, 0]\n",
    "                        subrect[0] = rect[0] + i * (rect[2] - rect[0]) * delta\n",
    "                        subrect[1] = rect[1] + j * (rect[3] - rect[1]) * delta\n",
    "                        subrect[2] = subrect[0] + (rect[2] - rect[0]) * slider_size\n",
    "                        subrect[3] = subrect[1] + (rect[3] - rect[1]) * slider_size\n",
    "                        d.rectangle(subrect, fill=\"black\", outline=None)\n",
    "                    datum_path = '{}_{}_{}_{}_{}_{}.jpeg'.format(path, type_str, 0, str(int(100 * slider_size)), str(i), str(j))\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))                    \n",
    "    \n",
    "    if type_str == 'crop_obj' or type_str == '1k_crop_obj':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, int(100 * slider_size))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for num in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    random_obj = obj_images[random.randint(0, len(obj_images) - 1)].copy()\n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    if ratio >= obj_ratio:\n",
    "                        resize_scale = float(height) / obj_height * slider_size\n",
    "                    else:\n",
    "                        resize_scale = float(width) / obj_width * slider_size\n",
    "                    new_width = int(obj_width * resize_scale)\n",
    "                    new_height = int(obj_height * resize_scale)\n",
    "                    if new_width == 0:\n",
    "                        new_width = 1\n",
    "                    if new_height == 0:\n",
    "                        new_height = 1\n",
    "                    random_obj = random_obj.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "                    \n",
    "                    rangex = [rect[0], rect[2] - random_obj.size[0]]\n",
    "                    if rangex[1] < rangex[0]:\n",
    "                        rangex[1] = rangex[0]\n",
    "                        \n",
    "                    rangey = [rect[1], rect[3] - random_obj.size[1]]\n",
    "                    if rangey[1] < rangey[0]:\n",
    "                        rangey[1] = rangey[0]\n",
    "                    top_left = (random.randint(rangex[0], rangex[1]), random.randint(rangey[0], rangey[1]))\n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "                    \n",
    "    if type_str == 'nocrop_obj' or type_str == '1k_nocrop_obj':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, 0, int(100 * slider_size))\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for num in range(slider_num):\n",
    "                img = img_orig.copy()\n",
    "                for rect_i, rect in enumerate(rects):\n",
    "                    random_obj = obj_images[random.randint(0, len(obj_images) - 1)].copy()\n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    if ratio >= obj_ratio:\n",
    "                        resize_scale = float(height) / obj_height * slider_size\n",
    "                    else:\n",
    "                        resize_scale = float(width) / obj_width * slider_size\n",
    "                    new_width = int(obj_width * resize_scale)\n",
    "                    new_height = int(obj_height * resize_scale)\n",
    "                    if new_width == 0:\n",
    "                        new_width = 1\n",
    "                    if new_height == 0:\n",
    "                        new_height = 1\n",
    "                    random_obj = random_obj.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "                    \n",
    "                    rangex = [rect[0], rect[2] - random_obj.size[0]]\n",
    "                    if rangex[1] < rangex[0]:\n",
    "                        rangex[1] = rangex[0]\n",
    "                        \n",
    "                    rangey = [rect[1], rect[3] - random_obj.size[1]]\n",
    "                    if rangey[1] < rangey[0]:\n",
    "                        rangey[1] = rangey[0]\n",
    "                    top_left = (random.randint(rangex[0], rangex[1]), random.randint(rangey[0], rangey[1]))\n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    \n",
    "                datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))              \n",
    "                    \n",
    "                    \n",
    "    if type_str == 'aperture' or type_str == '1k_aperture':\n",
    "        if slider_size == 0: # All black.\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                d = ImageDraw.Draw(img)\n",
    "                d.rectangle(rect, fill=\"black\", outline=None)\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        elif slider_size == 1: # All visible. \n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    for j in range(slider_num):\n",
    "                        img = img_orig.copy()\n",
    "                        d = ImageDraw.Draw(img)\n",
    "                        delta = (1 - slider_size) / float(slider_num - 1)\n",
    "                        subrect = [0, 0, 0, 0]\n",
    "                        subrect[0] = rect[0] + i * (rect[2] - rect[0]) * delta\n",
    "                        subrect[1] = rect[1] + j * (rect[3] - rect[1]) * delta\n",
    "                        subrect[2] = subrect[0] + (rect[2] - rect[0]) * slider_size\n",
    "                        subrect[3] = subrect[1] + (rect[3] - rect[1]) * slider_size\n",
    "                        d.rectangle([0, 0, img.size[0], subrect[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([0, 0, subrect[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([subrect[2], 0, img.size[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        d.rectangle([0, subrect[3], img.size[0], img.size[1]], fill=\"black\", outline=None)\n",
    "                        img = img.crop(rect)\n",
    "                        datum_path = '{}_{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), str(i), str(j))\n",
    "                        img.save(datum_path)\n",
    "                        f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "            \n",
    "if '1k' in type_str:\n",
    "    image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "    annotation_path =  imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/'\n",
    "else:\n",
    "    image_path = imagenet_root + 'image/'\n",
    "    annotation_path = imagenet_root + 'Annotation/'\n",
    "\n",
    "synset_names = os.listdir(image_path)\n",
    "            \n",
    "start_time = time.time()\n",
    "\n",
    "dataset_sum = training_dataset_size + test_dataset_size\n",
    "all_sum = len(synset_names) * dataset_sum\n",
    "print all_sum\n",
    "for synset_index, synset_name in enumerate(synset_names):\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    annotation_names = os.listdir(annotation_path + synset_name)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    for i in range(dataset_sum):\n",
    "        if (i + 1) % 50 == 0:\n",
    "            second = int(time.time() - start_time)\n",
    "            now_time = time.strftime(\"%H:%M:%S\", time.gmtime(second))\n",
    "            now_sum = synset_index * dataset_sum + i\n",
    "            \n",
    "            estimated = int(float(all_sum) / now_sum * second)\n",
    "            estimated_time = time.strftime(\"%H:%M:%S\", time.gmtime(estimated))\n",
    "            estimated_day = estimated / 3600 / 24\n",
    "            print '[{}/{} {}]Processing synset [{}/{}], image [{}/{}]: {}'.format(now_time, estimated_day, estimated_time, synset_index + 1, len(synset_names), i + 1, dataset_sum, intersection_names[i])\n",
    "        # Read bounding box.\n",
    "        bbx_file = open(annotation_path + synset_name + '/' + intersection_names[i] + '.xml')\n",
    "        xmltree = ET.parse(bbx_file)\n",
    "        objects = xmltree.findall('object')\n",
    "        rects = []\n",
    "        for obj in objects:\n",
    "            bbx = obj.find('bndbox')\n",
    "            rects.append([int(it.text) for it in bbx])\n",
    "            \n",
    "        img_orig = Image.open(image_path + synset_name + '/' + intersection_names[i] + '.JPEG')\n",
    "        \n",
    "        if '1k' in type_str:\n",
    "            class_id = wnid_to_label[synset_name]\n",
    "        else:\n",
    "            class_id = original_to_new_class_id[wnid_to_label[synset_name]]\n",
    "        \n",
    "        if i < training_dataset_size: # Training dataset. \n",
    "            for index, (slider_size, slider_num) in enumerate(training_dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(train_folders[index], intersection_names[i]), \\\n",
    "                               train_files[index], class_id, rects, slider_size, slider_num)\n",
    "        else: # Testing dataset.\n",
    "            for index, (slider_size, slider_num) in enumerate(test_dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(test_folders[index], intersection_names[i]), \\\n",
    "                               test_files[index], class_id, rects, slider_size, slider_num)\n",
    "            \n",
    "for f in train_files:\n",
    "    f.close()\n",
    "for f in test_files:\n",
    "    f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample or for lmdb.\n",
    "\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "import shutil\n",
    "\n",
    "mode = 'sample'\n",
    "is_lmdb = True\n",
    "\n",
    "func_strs = ['train', 'test']\n",
    "type_strs = ['1k_crop_obj', '1k_nocrop_obj']\n",
    "names = ['0', '20', '40', '60', '80', '100']\n",
    "sample_sum = {'train': 100000, 'test': 50000}\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        for name in names:\n",
    "            #shutil.copyfile('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), \\\n",
    "            #         '{}dataset/{}_{}_{}_unsampled.txt'.format(imagenet_root, func_str, type_str, name))\n",
    "            with open('{}dataset/{}_{}_{}_unsampled.txt'.format(imagenet_root, func_str, type_str, name)) as f:\n",
    "                lines = f.readlines()\n",
    "            if mode == 'nosample':\n",
    "                sampled = lines\n",
    "            else:\n",
    "                sampled = random.sample(lines, sample_sum[func_str])\n",
    "            if is_lmdb:\n",
    "                for i in range(len(sampled)):\n",
    "                    sampled[i] = sampled[i].split('/')[-2] + '/' + sampled[i].split('/')[-1]\n",
    "            with open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), 'w') as f:\n",
    "                f.writelines(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create {}_{}_all.txt.\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "\n",
    "dataset = [(0.0, 0), (0.2, 9), (0.4, 9), (0.6, 9), (0.8, 9), (1.0, 9)] # when crop_obj or nocrop_obj, (size, total_num)\n",
    "\n",
    "type_strs = ['1k_crop_obj', '1k_nocrop_obj']\n",
    "func_strs = ['train', 'test']\n",
    "#sample_sum = {'train': {'1k_crop_obj': 1016757, '1k_nocrop_obj': 900000}, \\\n",
    "#              'test': {'1k_crop_obj': 509238, '1k_nocrop_obj': 450000}}\n",
    "sample_sum = {'train': {'1k_crop_obj': 100000, '1k_nocrop_obj': 100000}, \\\n",
    "              'test': {'1k_crop_obj': 50000, '1k_nocrop_obj': 50000}}\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        lines = []\n",
    "        for size, num in dataset:\n",
    "            percent = int(size * 100)\n",
    "            f = open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, percent), 'r')\n",
    "            ls = f.readlines()\n",
    "            f.close()\n",
    "            lines = lines + ls\n",
    "        f = open('{}dataset/{}_{}_all_unsampled.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        sampled = random.sample(lines, sample_sum[func_str][type_str])\n",
    "        f = open('{}dataset/{}_{}_all.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(sampled)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%file transparent.py\n",
    "# Make white color transparent.\n",
    "from constant import *\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_names = os.listdir(shapenet_root + 'object_orig/')\n",
    "print len(image_names)\n",
    "\n",
    "for i, image_name in enumerate(image_names):\n",
    "    print '[{}/{}]: {}'.format(i, len(image_names), image_name)\n",
    "    img = Image.open(shapenet_root + 'object_orig/' + image_name)\n",
    "    \n",
    "    img = img.convert(\"RGBA\")\n",
    "    pixdata = img.load()\n",
    "    for y in xrange(img.size[1]):\n",
    "        for x in xrange(img.size[0]):\n",
    "            if pixdata[x, y] == (255, 255, 255, 255):\n",
    "                pixdata[x, y] = (255, 255, 255, 0)\n",
    "    img.save(shapenet_root + 'object_nobg/' + image_name, 'PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show typical images of each class.\n",
    "from constant import *\n",
    "import os\n",
    "import numpy as np\n",
    "#from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "with open(imagenet_labels_filename) as f:\n",
    "    lines = f.readlines()\n",
    "wnid_to_name = {}\n",
    "for line in lines:\n",
    "    wnid = line.split(' ')[0]\n",
    "    name = line[(len(wnid) + 1):-1]\n",
    "    wnid_to_name[wnid] = name\n",
    "\n",
    "synset_names = os.listdir(imagenet_root + 'image/')\n",
    "for synset_name in synset_names:\n",
    "    image_names = os.listdir(imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images')\n",
    "    print wnid_to_name[synset_name], 'http://image-net.org/synset?wnid=' + synset_name\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[42]))\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[32]))\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[22]))\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[12]))\n",
    "    display(Image(filename=imagenet_root + 'image/' + synset_name + '/' + synset_name + '_original_images/' + image_names[0]))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity check.\n",
    "import os\n",
    "from constant import *\n",
    "\n",
    "func_strs = ['train', 'test']\n",
    "type_strs = ['1k_nocrop_obj', '1k_crop_obj']\n",
    "dataset = [(0.0, 0), (0.2, 9), (0.4, 9), (0.6, 9), (0.8, 9), (1.0, 9)] # when crop_obj or nocrop_obj, (size, total_num)\n",
    "\n",
    "\n",
    "for filename in sorted(os.listdir(imagenet_root + 'dataset/')):\n",
    "    for func_str in func_strs:\n",
    "        for type_str in type_strs:\n",
    "            if '{}_{}'.format(func_str, type_str) in filename and '.txt' in filename:\n",
    "                f = open(imagenet_root + 'dataset/' + filename)\n",
    "                lines = f.readlines()\n",
    "                print '{:10d} {}'.format(len(lines), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from constant import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f = open(caffe_root + 'data/ilsvrc12/synset_words.txt')\n",
    "label_to_wnid = f.readlines()\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "folders = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/')\n",
    "count = []\n",
    "for folder in folders:\n",
    "    image_names = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/' + folder)\n",
    "    annotation_names = os.listdir(imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/' + folder)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    count.append(len(intersection_names))\n",
    "\n",
    "x = [i for i in range(len(count))]\n",
    "count = sorted(count)\n",
    "plt.plot(x, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
