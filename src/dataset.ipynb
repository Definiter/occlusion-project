{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%file dataset.py\n",
    "# Generate training dataset and test dataset.\n",
    "from constant import *\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import argparse\n",
    "import math\n",
    "import act_max as act\n",
    "import scipy.misc, scipy.io\n",
    "#import caffe\n",
    "\n",
    "#### Parameters. ####\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_index', required=True)\n",
    "parser.add_argument('--type_str', required=True)\n",
    "#parser.add_argument('--gpu', required=False)\n",
    "args = parser.parse_args()\n",
    "\n",
    "#type_str = 'crop_img' # {1k_}[crop | nocrop | crop_obj | nocrop_obj | aperture | crop_img ]\n",
    "type_str = args.type_str\n",
    "\n",
    "#dataset = [(0.0, 0),  (0.1, 10), (0.2, 10), (0.3, 10), (0.4, 10),\\\n",
    "#           (0.5, 10), (0.6, 10), (0.7, 10), (0.8, 10), (0.9, 10), (1.0, 1)]\n",
    "dataset = [(0.0, 0),  (0.1, 1), (0.2, 1), (0.3, 1), (0.4, 1),\\\n",
    "           (0.5, 1), (0.6, 1), (0.7, 1), (0.8, 1), (0.9, 1), (1.0, 1)]\n",
    "dataset_index = int(args.dataset_index)\n",
    "#dataset_index = 5\n",
    "print 'Processsing dataset {}, type_str {}'.format(dataset[dataset_index], type_str)\n",
    "dataset = [dataset[dataset_index]]\n",
    "\n",
    "'''\n",
    "if args.gpu != None:\n",
    "    gpu = int(args.gpu)\n",
    "    caffe.set_device(gpu)\n",
    "    caffe.set_mode_gpu()\n",
    "'''\n",
    "#caffe.set_mode_gpu()\n",
    "\n",
    "# divide to training dataset and test dataset\n",
    "training_dataset_size = 300\n",
    "validation_dataset_size = 100\n",
    "test_dataset_size = 100\n",
    "\n",
    "#####################\n",
    "\n",
    "mean_color = (123, 117, 104)\n",
    "\n",
    "# Load labels.\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "label_to_wnid = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "train_folders = []\n",
    "val_folders = []\n",
    "test_folders = []\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/train_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    train_files.append(f)\n",
    "    \n",
    "    folder = '{}dataset/train_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    train_folders.append(folder)\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/val_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    val_files.append(f)\n",
    "\n",
    "    folder = '{}dataset/val_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    val_folders.append(folder)\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/test_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    test_files.append(f)\n",
    "\n",
    "    folder = '{}dataset/test_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    test_folders.append(folder)\n",
    "    \n",
    "# Initialization for 'obj'.\n",
    "if 'obj' in type_str:\n",
    "    obj_images = []\n",
    "    for i, image_name in enumerate(os.listdir(shapenet_root + 'object_crop/')):\n",
    "        img_temp = Image.open(shapenet_root + 'object_crop/' + image_name)\n",
    "        img = img_temp.copy()\n",
    "        img_temp.close()\n",
    "        #img = img.convert(\"RGBA\")\n",
    "        obj_images.append(img)\n",
    "    print \"{} object occluders loaded.\".format(len(obj_images))\n",
    "    \n",
    "'''\n",
    "# On-the-fly generation.\n",
    "# Initialization for 'imagination'.\n",
    "if type_str == 'crop_img':\n",
    "    act_args = lambda: None\n",
    "    act_args.xy = 0\n",
    "    act_args.n_iters = 200\n",
    "    act_args.L2 = 0.99\n",
    "    act_args.start_lr = 8.0\n",
    "    act_args.end_lr = 1e-10\n",
    "    act_args.seed = 0\n",
    "    act_args.opt_layer = \"fc6\"\n",
    "    act_args.act_layer = \"fc8_occlusion\"\n",
    "    act_args.init_file = \"None\"\n",
    "    act_args.clip = 0\n",
    "    act_args.bound = synthesizing_root + \"act_range/3x/fc6.txt\"\n",
    "    act_args.debug = 0\n",
    "    act_args.output_dir = synthesizing_root + \"output/baseline\"\n",
    "\n",
    "    act_args.net_weights = result_root + \"model/finetune_alexnet_crop_0/finetune_alexnet_crop_0.caffemodel\"\n",
    "    act_args.net_definition = result_root + \"model/finetune_alexnet_crop_0/deploy.prototxt\"\n",
    "    act_args.generator_weights = synthesizing_root + \"nets/upconv/fc6/generator.caffemodel\"\n",
    "    act_args.generator_definition = synthesizing_root + \"nets/upconv/fc6/generator.prototxt\"\n",
    "    act_args.encoder_weights = synthesizing_root + \"nets/caffenet/bvlc_reference_caffenet.caffemodel\"\n",
    "    act_args.encoder_definition = synthesizing_root + \"nets/caffenet/caffenet.prototxt\"\n",
    "\n",
    "    params = [\n",
    "        {\n",
    "            'layer': act_args.act_layer,\n",
    "            'iter_n': act_args.n_iters,\n",
    "            'L2': act_args.L2,\n",
    "            'start_step_size': act_args.start_lr,\n",
    "            'end_step_size': act_args.end_lr\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Networks.\n",
    "    generator = caffe.Net(act_args.generator_definition, act_args.generator_weights, caffe.TEST)\n",
    "    net = caffe.Classifier(act_args.net_definition, act_args.net_weights,\n",
    "            mean = np.float32([104.0, 117.0, 123.0]), # ImageNet mean\n",
    "            channel_swap = (2,1,0)) # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "    # input / output layers in generator\n",
    "    gen_in_layer = \"feat\"\n",
    "    gen_out_layer = \"deconv0\"\n",
    "\n",
    "    # shape of the code being optimized\n",
    "    shape = generator.blobs[gen_in_layer].data.shape\n",
    "\n",
    "    # Fix the seed\n",
    "    np.random.seed(act_args.seed)\n",
    "'''\n",
    "\n",
    "# Initialization for 'crop_img'.\n",
    "if type_str == 'crop_img':\n",
    "    img_images = []\n",
    "    for class_id in range(100):\n",
    "        for num in range(20):\n",
    "            filename = '{}_{}.jpg'.format(class_id, num)\n",
    "            img_temp = Image.open(imagenet_root + 'synthesized/' + filename)\n",
    "            img = img_temp.copy()\n",
    "            img_temp.close()\n",
    "            img_images.append(img)\n",
    "    print \"{} synthesized images loaded.\".format(len(img_images))\n",
    "    \n",
    "\n",
    "\n",
    "# occluder size = slider_size * slider_size\n",
    "# occluder num = slider_num * slider_num\n",
    "# path = 'imagenet_root/dataset/train_0/name'\n",
    "# {wnid_imgid}_{crop/nocrop}_{rect_i(ifcrop)}_{slider_size}_{i}_{j}\n",
    "def generate_datum(img_orig, path, f, class_id, rects, slider_size, slider_num):\n",
    "    if type_str == 'crop' or type_str == '1k_crop':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "                    d.rectangle(subrect, fill=mean_color, outline=None)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "    if type_str == 'nocrop' or type_str == '1k_nocrop':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_0_0_0.jpeg'.format(path, type_str)\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for i in range(slider_num):\n",
    "                img = img_orig.copy()\n",
    "                d = ImageDraw.Draw(img)\n",
    "                for rect in rects:\n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "                    d.rectangle(subrect, fill=mean_color, outline=None)\n",
    "                datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, 0, str(int(100 * slider_size)), i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))   \n",
    "                \n",
    "                \n",
    "    if type_str == 'aperture' or type_str == '1k_aperture':\n",
    "        if slider_size == 0: # All gray.\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                d = ImageDraw.Draw(img)\n",
    "                d.rectangle(rect, fill=mean_color, outline=None)\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        elif slider_size == 1: # All visible. \n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    \n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    \n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "\n",
    "                    d.rectangle([0, 0, img.size[0], subrect[1]], fill=mean_color, outline=None)\n",
    "                    d.rectangle([0, 0, subrect[0], img.size[1]], fill=mean_color, outline=None)\n",
    "                    d.rectangle([subrect[2], 0, img.size[0], img.size[1]], fill=mean_color, outline=None)\n",
    "                    d.rectangle([0, subrect[3], img.size[0], img.size[1]], fill=mean_color, outline=None)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "    \n",
    "    if type_str == 'crop_obj' or type_str == '1k_crop_obj':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, int(100 * slider_size))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for num in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    random_obj = obj_images[random.randint(0, len(obj_images) - 1)].copy()\n",
    "                    obj_width = random_obj.size[0]\n",
    "                    obj_height = random_obj.size[1]\n",
    "                    obj_ratio = float(obj_width) / obj_height\n",
    "                    \n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    \n",
    "                    max_occlusion = 0.0\n",
    "                    if ratio >= obj_ratio:\n",
    "                        max_occlusion = obj_width * height / float(width * obj_height)\n",
    "                    else:\n",
    "                        max_occlusion = width * obj_height / float(height * obj_width)\n",
    "                    \n",
    "                    if max_occlusion >= slider_size:\n",
    "                        # Do not need to stretch and change obj_ratio.\n",
    "                        new_width = (slider_size * width * height * obj_width / float(obj_height)) ** 0.5\n",
    "                        new_height = (slider_size * width * height * obj_height / float(obj_width)) ** 0.5\n",
    "                    else:\n",
    "                        # Need to stretch and change obj_ratio.\n",
    "                        if ratio >= obj_ratio:\n",
    "                            new_width = width * slider_size\n",
    "                            new_height = height\n",
    "                        else:\n",
    "                            new_width = width\n",
    "                            new_height = height * slider_size\n",
    "                    new_width = int(new_width)\n",
    "                    new_height = int(new_height)\n",
    "                    if new_width == 0:\n",
    "                        new_width = 1\n",
    "                    if new_height == 0:\n",
    "                        new_height = 1\n",
    "                        \n",
    "                    random_obj = random_obj.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "                    \n",
    "                    top_left = (random.randint(rect[0], rect[2] - random_obj.size[0]),\\\n",
    "                                random.randint(rect[1], rect[3] - random_obj.size[1]))\n",
    "                    \n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "                    \n",
    "    if type_str == 'nocrop_obj' or type_str == '1k_nocrop_obj':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, 0, int(100 * slider_size))\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for num in range(slider_num):\n",
    "                img = img_orig.copy()\n",
    "                for rect_i, rect in enumerate(rects):\n",
    "                    random_obj = obj_images[random.randint(0, len(obj_images) - 1)].copy()\n",
    "                    \n",
    "                    obj_width = random_obj.size[0]\n",
    "                    obj_height = random_obj.size[1]\n",
    "                    obj_ratio = float(obj_width) / obj_height\n",
    "                    \n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    \n",
    "                    max_occlusion = 0.0\n",
    "                    if ratio >= obj_ratio:\n",
    "                        max_occlusion = obj_width * height / float(width * obj_height)\n",
    "                    else:\n",
    "                        max_occlusion = width * obj_height / float(height * obj_width)\n",
    "                    \n",
    "                    if max_occlusion >= slider_size:\n",
    "                        # Do not need to stretch and change obj_ratio.\n",
    "                        new_width = (slider_size * width * height * obj_width / float(obj_height)) ** 0.5\n",
    "                        new_height = (slider_size * width * height * obj_height / float(obj_width)) ** 0.5\n",
    "                    else:\n",
    "                        # Need to stretch and change obj_ratio.\n",
    "                        if ratio >= obj_ratio:\n",
    "                            new_width = width * slider_size\n",
    "                            new_height = height\n",
    "                        else:\n",
    "                            new_width = width\n",
    "                            new_height = height * slider_size\n",
    "                    new_width = int(new_width)\n",
    "                    new_height = int(new_height)\n",
    "                    if new_width == 0:\n",
    "                        new_width = 1\n",
    "                    if new_height == 0:\n",
    "                        new_height = 1\n",
    "                        \n",
    "                    random_obj = random_obj.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "                    \n",
    "                    top_left = (random.randint(rect[0], rect[2] - random_obj.size[0]),\\\n",
    "                                random.randint(rect[1], rect[3] - random_obj.size[1]))\n",
    "                    \n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    \n",
    "                datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id))) \n",
    "    \n",
    "    if type_str == \"crop_img\":\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "                    img_image = img_images[random.randint(0, 2000 - 1)]\n",
    "                    img.paste(img_image.resize((slider_width, slider_height)), (subrect[0], subrect[1]))\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    # On-the-fly generation.\n",
    "    if type_str == \"crop_img\":\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    act_args.unit = random.randint(0, 99)\n",
    "                    img = img_orig.copy()\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "                    \n",
    "                    act_args.init_file = '{}_{}_{}_{}_{}_init.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    img.crop(subrect).save(act_args.init_file)\n",
    "                    start_code, start_image = act.get_code(act_args.init_file, act_args.opt_layer)\n",
    "                    os.remove(act_args.init_file)\n",
    "                    \n",
    "                    #start_code, start_image = act.get_code2(np.array(img.crop(subrect)), act_args.opt_layer)\n",
    "                    \n",
    "                    # Load the activation range\n",
    "                    upper_bound = lower_bound = None\n",
    "                    # Set up clipping bounds\n",
    "                    if act_args.bound != \"\":\n",
    "                        n_units = shape[1]\n",
    "                        upper_bound = np.loadtxt(act_args.bound, delimiter=' ', usecols=np.arange(0, n_units), unpack=True)\n",
    "                        upper_bound = upper_bound.reshape(start_code.shape)\n",
    "                        # Lower bound of 0 due to ReLU\n",
    "                        lower_bound = np.zeros(start_code.shape)\n",
    "                    # Optimize a code via gradient ascent\n",
    "                    output_image = act.activation_maximization(net, generator, gen_in_layer, gen_out_layer, start_code, params, \n",
    "                            clip=act_args.clip, unit=act_args.unit, xy=act_args.xy, debug=act_args.debug,\n",
    "                            upper_bound=upper_bound, lower_bound=lower_bound)\n",
    "                    output_image = output_image[:,::-1, :, :] # Convert from BGR to RGB\n",
    "                    normalized_img = act.patchShow.patchShow_single(output_image, in_range=(-120,120))        \n",
    "                    normalized_img = np.uint8(normalized_img * 255)\n",
    "                    new_img = Image.fromarray(normalized_img)\n",
    "                    #img_file = '{}_{}_{}_{}_{}_img.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    #new_img.save(img_file)\n",
    "                    \n",
    "                    img.paste(new_img.resize((slider_width, slider_height)), (subrect[0], subrect[1]))\n",
    "                    img = img.crop(rect)\n",
    "                    \n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "    '''\n",
    "                    \n",
    "            \n",
    "image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "annotation_path =  imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/'\n",
    "\n",
    "if '1k' in type_str:\n",
    "    synset_names = os.listdir(image_path)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dataset_sum = training_dataset_size + validation_dataset_size + test_dataset_size\n",
    "all_sum = len(synset_names) * dataset_sum\n",
    "print all_sum\n",
    "\n",
    "for synset_index, synset_name in enumerate(synset_names):\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    annotation_names = os.listdir(annotation_path + synset_name)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    for i in range(dataset_sum):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            second = int(time.time() - start_time)\n",
    "            now_time = time.strftime(\"%H:%M:%S\", time.gmtime(second))\n",
    "            now_sum = synset_index * dataset_sum + i\n",
    "            \n",
    "            estimated = int(float(all_sum) / now_sum * second)\n",
    "            estimated_time = time.strftime(\"%H:%M:%S\", time.gmtime(estimated))\n",
    "            estimated_day = estimated / 3600 / 24\n",
    "            print '[{}/{} {}]Processing synset [{}/{}], image [{}/{}]: {}'.format(now_time, estimated_day, estimated_time, synset_index + 1, len(synset_names), i + 1, dataset_sum, intersection_names[i])\n",
    "        # Read bounding box.\n",
    "        bbx_file = open(annotation_path + synset_name + '/' + intersection_names[i] + '.xml')\n",
    "        xmltree = ET.parse(bbx_file)\n",
    "        objects = xmltree.findall('object')\n",
    "        rects = []\n",
    "        for obj in objects:\n",
    "            bbx = obj.find('bndbox')\n",
    "            rects.append([int(it.text) for it in bbx])\n",
    "            \n",
    "        img_orig = Image.open(image_path + synset_name + '/' + intersection_names[i] + '.JPEG')\n",
    "        if img_orig.mode != \"RGB\":\n",
    "            img_orig = img_orig.convert(\"RGB\")\n",
    "            \n",
    "        if '1k' in type_str:\n",
    "            class_id = wnid_to_label[synset_name]\n",
    "        else:\n",
    "            class_id = original_to_new_class_id[wnid_to_label[synset_name]]\n",
    "        \n",
    "        if i < training_dataset_size: # Training dataset. \n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(train_folders[index], intersection_names[i]), \\\n",
    "                               train_files[index], class_id, rects, slider_size, slider_num)\n",
    "        elif i < training_dataset_size + validation_dataset_size: # Validation dataset\n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(val_folders[index], intersection_names[i]), \\\n",
    "                               val_files[index], class_id, rects, slider_size, slider_num)\n",
    "        else: # Test dataset.\n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(test_folders[index], intersection_names[i]), \\\n",
    "                               test_files[index], class_id, rects, slider_size, slider_num)\n",
    "                               \n",
    "for f in train_files:\n",
    "    f.close()\n",
    "for f in test_files:\n",
    "    f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample or for lmdb.\n",
    "\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "import shutil\n",
    "\n",
    "#mode = 'nosample'\n",
    "mode = 'sampl'\n",
    "is_lmdb = True\n",
    "\n",
    "func_strs = ['train', 'val', 'test']\n",
    "type_strs = ['every_grs']\n",
    "#names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100']\n",
    "names = ['all']\n",
    "sample_sum = {'train': 343360, 'test': 114060, 'val': 114010}\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        for name in names:\n",
    "            #shutil.copyfile('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), \\\n",
    "            #         '{}dataset/{}_{}_{}_unsampled.txt'.format(imagenet_root, func_str, type_str, name))\n",
    "            with open('{}dataset/{}_{}_{}_unsampled.txt'.format(imagenet_root, func_str, type_str, name)) as f:\n",
    "                lines = f.readlines()\n",
    "            if mode == 'nosample':\n",
    "                sampled = lines\n",
    "            else:\n",
    "                sampled = random.sample(lines, sample_sum[func_str])\n",
    "            if is_lmdb:\n",
    "                for i in range(len(sampled)):\n",
    "                    sampled[i] = sampled[i].split('/')[-2] + '/' + sampled[i].split('/')[-1]\n",
    "            with open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), 'w') as f:\n",
    "                f.writelines(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create {}_{}_all.txt.\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "\n",
    "func_strs = ['train', 'val', 'test']\n",
    "type_strs = ['crop_img']\n",
    "names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100']\n",
    "#names = ['0', '20', '40', '60', '80', '100']\n",
    "\n",
    "#sample_sum = {'train': {'crop': 343360, 'nocrop': 300000}, \\\n",
    "#              'val': {'crop': 114010, 'nocrop': 100000}, \\\n",
    "#              'test': {'crop': 114060, 'nocrop': 100000}}\n",
    "\n",
    "#sample_sum = {'train': {'aperture': 343360}, \\\n",
    "#              'val': {'aperture': 114010}, \\\n",
    "#              'test': {'aperture': 114060}}\n",
    "\n",
    "#sample_sum = {'train': {'crop_obj': 343360}, \\\n",
    "#              'val': {'crop_obj': 114010}, \\\n",
    "#              'test': {'crop_obj': 114060}}\n",
    "\n",
    "\n",
    "#sample_sum = {'train': {'every': 343360}, \\\n",
    "#              'val': {'every': 114010}, \\\n",
    "#              'test': {'every': 114060}}\n",
    "\n",
    "#sample_sum = {'train': {'crop_img': 343360}, \\\n",
    "#              'val': {'crop_img': 114010}, \\\n",
    "#              'test': {'crop_img': 114060}}\n",
    "\n",
    "\n",
    "sample_sum = {'train': {'every_grs': 343360}, \\\n",
    "              'val': {'every_grs': 114010}, \\\n",
    "              'test': {'every_grs': 114060}}\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        lines = []\n",
    "        for name in names:\n",
    "            f = open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), 'r')\n",
    "            ls = f.readlines()\n",
    "            f.close()\n",
    "            lines = lines + ls\n",
    "        f = open('{}dataset/{}_{}_all_unsampled.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        sampled = random.sample(lines, sample_sum[func_str][type_str])\n",
    "        f = open('{}dataset/{}_{}_all.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(sampled)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_0.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_10.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_20.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_30.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_40.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_50.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_60.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_70.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_80.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_90.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_img_100.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_img_all.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_0.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_10.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_20.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_30.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_40.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_50.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_60.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_70.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_80.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_90.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_img_100.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_img_all.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_0.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_10.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_20.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_30.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_40.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_50.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_60.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_70.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_80.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_90.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_img_100.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_img_all.txt\n"
     ]
    }
   ],
   "source": [
    "# Sanity check.\n",
    "import os\n",
    "from constant import *\n",
    "\n",
    "func_strs = ['train', 'val', 'test']\n",
    "type_strs = ['crop_img']\n",
    "names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100', 'all']\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        for name in names:\n",
    "            filename = '{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name) \n",
    "            f = open(filename)\n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            print '{:10d} {}'.format(len(lines), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%file transparent.py\n",
    "# Make white color transparent and crop bounding box. For nocrop_obj/crop_obj.\n",
    "from constant import *\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_names = os.listdir(shapenet_root + 'object_orig/')\n",
    "print len(image_names)\n",
    "\n",
    "ratio = []\n",
    "\n",
    "for i, image_name in enumerate(image_names):\n",
    "    print '[{}/{}]: {}'.format(i, len(image_names), image_name)\n",
    "    img = Image.open(shapenet_root + 'object_orig/' + image_name)\n",
    "    \n",
    "    img = img.convert(\"RGBA\")\n",
    "    pixdata = img.load()\n",
    "    \n",
    "    scanline_x = np.zeros(img.size[0])\n",
    "    scanline_y = np.zeros(img.size[1])\n",
    "    \n",
    "    for x in xrange(img.size[0]):\n",
    "        for y in xrange(img.size[1]):\n",
    "            if pixdata[x, y] == (255, 255, 255, 255):\n",
    "                pixdata[x, y] = (255, 255, 255, 0)\n",
    "            else:\n",
    "                scanline_x[x] = 1\n",
    "                scanline_y[y] = 1\n",
    "                \n",
    "    # Get bounding box.\n",
    "    rect = [0, 0, 0, 0]\n",
    "    for i in range(len(scanline_x)):\n",
    "        if scanline_x[i] != 0:\n",
    "            rect[0] = i\n",
    "            break\n",
    "    for i in range(len(scanline_x)):\n",
    "        if scanline_x[len(scanline_x) - i - 1] != 0:\n",
    "            rect[2] = len(scanline_x) - i - 1\n",
    "            break\n",
    "    for i in range(len(scanline_y)):\n",
    "        if scanline_y[i] != 0:\n",
    "            rect[1] = i\n",
    "            break\n",
    "    for i in range(len(scanline_y)):\n",
    "        if scanline_y[len(scanline_y) - i - 1] != 0:\n",
    "            rect[3] = len(scanline_y) - i - 1\n",
    "            break\n",
    "            \n",
    "    ratio.append((rect[2] - rect[0]) / (rect[3] - rect[1]))\n",
    "            \n",
    "    img = img.crop(rect)\n",
    "            \n",
    "    img.save(shapenet_root + 'object_crop/' + image_name, 'PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from constant import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f = open(caffe_root + 'data/ilsvrc12/synset_words.txt')\n",
    "label_to_wnid = f.readlines()\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "folders = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/')\n",
    "count = []\n",
    "for folder in folders:\n",
    "    image_names = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/' + folder)\n",
    "    annotation_names = os.listdir(imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/' + folder)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    count.append(len(intersection_names))\n",
    "\n",
    "x = [i for i in range(len(count))]\n",
    "count = sorted(count)\n",
    "plt.plot(x, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Randomly sample classes for experiment.\n",
    "import os\n",
    "from constant import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "label_to_wnid = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "\n",
    "synset_name_to_original_id = {}\n",
    "for original_id in range(len(label_to_wnid)):\n",
    "    synset_name = label_to_wnid[original_id].split(' ')[0]\n",
    "    synset_name_to_original_id[synset_name] = original_id\n",
    "\n",
    "image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "annotation_path =  imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/'\n",
    "\n",
    "count = []\n",
    "sampled = []\n",
    "for synset_index, synset_name in enumerate(os.listdir(image_path)):\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    annotation_names = os.listdir(annotation_path + synset_name)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    count.append(len(intersection_names))\n",
    "    if len(intersection_names) >= 500:\n",
    "        sampled.append(synset_name)\n",
    "\n",
    "count = sorted(count)\n",
    "plt.plot(count)\n",
    "\n",
    "sampled = random.sample(sampled, 100)\n",
    "print sampled\n",
    "\n",
    "new_to_original_class_id = []\n",
    "original_to_new_class_id = {}\n",
    "for synset_name in sampled:\n",
    "    new_to_original_class_id.append(synset_name_to_original_id[synset_name])\n",
    "new_to_original_class_id = sorted(new_to_original_class_id)\n",
    "print new_to_original_class_id\n",
    "\n",
    "for i, original_id in enumerate(new_to_original_class_id):\n",
    "    original_to_new_class_id[original_id] = i\n",
    "print original_to_new_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate label list.\n",
    "import os\n",
    "from constant import *\n",
    "\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "lines = open(imagenet_labels_filename).readlines()\n",
    "\n",
    "original_id_to_name = []\n",
    "for line in lines:\n",
    "    wnid = line.split(' ')[0]\n",
    "    name = line[(len(wnid) + 1):-1]\n",
    "    original_id_to_name.append(name)\n",
    "    \n",
    "    \n",
    "label = [None for i in range(len(synset_names))]\n",
    "\n",
    "for new_id, original_id in enumerate(new_to_original_class_id):\n",
    "    label[new_id] = original_id_to_name[original_id]\n",
    "    print label[new_id]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:04/0 00:09:40] class: 0, num: 1\n",
      "[00:00:23/0 00:09:15] class: 1, num: 1\n",
      "[00:00:43/0 00:09:26] class: 2, num: 1\n",
      "[00:01:03/0 00:09:30] class: 3, num: 1\n",
      "[00:01:22/0 00:09:26] class: 4, num: 1\n",
      "[00:01:42/0 00:09:28] class: 5, num: 1\n",
      "[00:02:02/0 00:09:30] class: 6, num: 1\n",
      "[00:02:21/0 00:09:27] class: 7, num: 1\n",
      "[00:02:42/0 00:09:32] class: 8, num: 1\n",
      "[00:03:05/0 00:09:43] class: 9, num: 1\n",
      "[00:03:27/0 00:09:48] class: 10, num: 1\n",
      "[00:03:50/0 00:09:55] class: 11, num: 1\n",
      "[00:04:12/0 00:09:59] class: 12, num: 1\n",
      "[00:04:34/0 00:10:01] class: 13, num: 1\n",
      "[00:04:56/0 00:10:04] class: 14, num: 1\n",
      "[00:05:19/0 00:10:08] class: 15, num: 1\n",
      "[00:05:41/0 00:10:10] class: 16, num: 1\n",
      "[00:06:03/0 00:10:12] class: 17, num: 1\n",
      "[00:06:26/0 00:10:15] class: 18, num: 1\n",
      "[00:06:48/0 00:10:16] class: 19, num: 1\n",
      "[00:07:10/0 00:10:17] class: 20, num: 1\n",
      "[00:07:32/0 00:10:18] class: 21, num: 1\n",
      "[00:07:52/0 00:10:16] class: 22, num: 1\n",
      "[00:08:11/0 00:10:13] class: 23, num: 1\n",
      "[00:08:31/0 00:10:12] class: 24, num: 1\n",
      "[00:08:51/0 00:10:11] class: 25, num: 1\n",
      "[00:09:10/0 00:10:08] class: 26, num: 1\n",
      "[00:09:30/0 00:10:07] class: 27, num: 1\n",
      "[00:09:49/0 00:10:05] class: 28, num: 1\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Synthesize occluders.\n",
    "import os\n",
    "from constant import *\n",
    "import caffe\n",
    "import numpy as np\n",
    "caffe.set_mode_gpu() # uncomment this if gpu processing is available\n",
    "import act_max as act\n",
    "import time\n",
    "\n",
    "# Parameters.\n",
    "act_args = lambda: None\n",
    "act_args.xy = 0\n",
    "act_args.n_iters = 200\n",
    "act_args.L2 = 0.99\n",
    "act_args.start_lr = 8.0\n",
    "act_args.end_lr = 1e-10\n",
    "act_args.seed = 0\n",
    "act_args.opt_layer = \"fc6\"\n",
    "act_args.act_layer = \"fc8_occlusion\"\n",
    "act_args.init_file = \"None\"\n",
    "act_args.clip = 0\n",
    "act_args.bound = synthesizing_root + \"act_range/3x/fc6.txt\"\n",
    "act_args.debug = 0\n",
    "act_args.output_dir = synthesizing_root + \"output/baseline\"\n",
    "\n",
    "#act_args.net_weights = result_root + \"model/finetune_alexnet_nocrop_0/finetune_alexnet_nocrop_0.caffemodel\"\n",
    "#act_args.net_definition = result_root + \"model/finetune_alexnet_nocrop_0/deploy.prototxt\"\n",
    "act_args.net_weights = result_root + \"model/finetune_alexnet_shapenet_all/finetune_alexnet_shapenet_all.caffemodel\"\n",
    "act_args.net_definition = result_root + \"model/finetune_alexnet_shapenet_all/deploy.prototxt\"\n",
    "act_args.generator_weights = synthesizing_root + \"nets/upconv/fc6/generator.caffemodel\"\n",
    "act_args.generator_definition = synthesizing_root + \"nets/upconv/fc6/generator.prototxt\"\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'layer': act_args.act_layer,\n",
    "        'iter_n': act_args.n_iters,\n",
    "        'L2': act_args.L2,\n",
    "        'start_step_size': act_args.start_lr,\n",
    "        'end_step_size': act_args.end_lr\n",
    "    }\n",
    "]\n",
    "\n",
    "# Networks.\n",
    "generator = caffe.Net(act_args.generator_definition, act_args.generator_weights, caffe.TEST)\n",
    "net = caffe.Classifier(act_args.net_definition, act_args.net_weights,\n",
    "        mean = np.float32([104.0, 117.0, 123.0]), # ImageNet mean\n",
    "        channel_swap = (2,1,0)) # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "# input / output layers in generator\n",
    "gen_in_layer = \"feat\"\n",
    "gen_out_layer = \"deconv0\"\n",
    "\n",
    "# shape of the code being optimized\n",
    "shape = generator.blobs[gen_in_layer].data.shape\n",
    "\n",
    "# Fix the seed\n",
    "np.random.seed(act_args.seed)\n",
    "\n",
    "if act_args.init_file != \"None\":\n",
    "    start_code, start_image = act.get_code(act_args.init_file, act_args.opt_layer)\n",
    "    print \"Loaded start code: \", start_code.shape\n",
    "else:\n",
    "    start_code = np.random.normal(0, 1, shape)\n",
    "\n",
    "# Load the activation range\n",
    "upper_bound = lower_bound = None\n",
    "\n",
    "# Set up clipping bounds\n",
    "if act_args.bound != \"\":\n",
    "    n_units = shape[1]\n",
    "    upper_bound = np.loadtxt(act_args.bound, delimiter=' ', usecols=np.arange(0, n_units), unpack=True)\n",
    "    upper_bound = upper_bound.reshape(start_code.shape)\n",
    "\n",
    "    # Lower bound of 0 due to ReLU\n",
    "    lower_bound = np.zeros(start_code.shape)\n",
    "\n",
    "#class_sum = 100\n",
    "#num_sum = 5\n",
    "\n",
    "class_sum = 29\n",
    "num_sum = 5\n",
    "\n",
    "start_time = time.time()\n",
    "for class_id in range(class_sum):\n",
    "    act_args.unit = class_id\n",
    "    for num in range(num_sum):\n",
    "        start_code = np.random.normal(0, 1, shape)\n",
    "        # Optimize a code via gradient ascent\n",
    "        output_image = act.activation_maximization(net, generator, gen_in_layer, gen_out_layer, start_code, params, \n",
    "                clip=act_args.clip, unit=act_args.unit, xy=act_args.xy, debug=act_args.debug,\n",
    "                upper_bound=upper_bound, lower_bound=lower_bound)\n",
    "        # Save image\n",
    "        act.save_image(output_image, '{}synthesized/{}_{}.jpg'.format(shapenet_root, class_id, num))\n",
    "        \n",
    "        if num % 5 == 0:\n",
    "            second = int(time.time() - start_time)\n",
    "            now_time = time.strftime(\"%H:%M:%S\", time.gmtime(second))\n",
    "\n",
    "            estimated = int(float(class_sum * num_sum) / (class_id * num_sum + num + 1) * second)\n",
    "            estimated_time = time.strftime(\"%H:%M:%S\", time.gmtime(estimated))\n",
    "            estimated_day = estimated / 3600 / 24\n",
    "            print '[{}/{} {}] class: {}, num: {}'.format(now_time, estimated_day, estimated_time, class_id, num + 1)\n",
    "\n",
    "        \n",
    "if act_args.debug:\n",
    "    act.save_image(output_image, \"./debug/%s.jpg\" % str(act_args.n_iters).zfill(3))\n",
    "    \n",
    "print 'done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=227x227 at 0x2B1B5002CA50>\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean image.\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "from constant import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "img_images = []\n",
    "for class_id in range(100):\n",
    "    filename = '{}_{}.jpg'.format(class_id, random.randint(0, 4))\n",
    "    img = Image.open(imagenet_root + 'synthesized/' + filename)\n",
    "    img_images.append(img)\n",
    "\n",
    "avg = np.array(img_images[0], dtype = np.float32)\n",
    "for i in range(1, 100):\n",
    "    avg = avg + np.array(img_images[i])\n",
    "avg /= 100\n",
    "m = Image.fromarray(np.uint8(avg))\n",
    "print m\n",
    "m.save(imagenet_root + 'synthesized/mean.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
