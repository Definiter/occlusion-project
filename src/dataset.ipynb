{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%file dataset.py\n",
    "# Generate training dataset and test dataset.\n",
    "from constant import *\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "#### Parameters. ####\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_index', required=True)\n",
    "parser.add_argument('--type_str', required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "#type_str = 'crop_obj' # {1k_}[crop | nocrop | crop_obj | nocrop_obj | aperture]\n",
    "type_str = args.type_str\n",
    "\n",
    "#dataset = [(0.0, 0), (1.0/4, 4), (1.0/3, 3), (1.0/2, 3), (2.0/3, 3), (4.0/5, 3), (9.0/10, 3), (1.0, 1)]\n",
    "#dataset = [(0.0, 0), (0.1, 10), (0.2, 5), (0.3, 4), (0.4, 3), (0.5, 3), (0.6, 3), (0.7, 3), (0.8, 3), (0.9, 3), (1.0, 1)]\n",
    "#dataset = [(0.0, 0), (0.2, 9), (0.4, 9), (0.6, 9), (0.8, 9), (1.0, 9)] # when crop_obj or nocrop_obj, (size, total_num)\n",
    "dataset = [(0.0, 0),  (0.1, 10), (0.2, 10), (0.3, 10), (0.4, 10),\\\n",
    "           (0.5, 10), (0.6, 10), (0.7, 10), (0.8, 10), (0.9, 10), (1.0, 1)]\n",
    "dataset_index = int(args.dataset_index)\n",
    "#dataset_index = 7\n",
    "print 'Processsing dataset {}, type_str {}'.format(dataset[dataset_index], type_str)\n",
    "dataset = [dataset[dataset_index]]\n",
    "\n",
    "# divide to training dataset and test dataset\n",
    "training_dataset_size = 300\n",
    "validation_dataset_size = 100\n",
    "test_dataset_size = 100\n",
    "\n",
    "#####################\n",
    "\n",
    "mean_color = (123, 117, 104)\n",
    "\n",
    "# Load labels.\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "label_to_wnid = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "train_folders = []\n",
    "val_folders = []\n",
    "test_folders = []\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/train_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    train_files.append(f)\n",
    "    \n",
    "    folder = '{}dataset/train_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    train_folders.append(folder)\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/val_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    val_files.append(f)\n",
    "\n",
    "    folder = '{}dataset/val_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    val_folders.append(folder)\n",
    "\n",
    "for (slider_size, slider_num) in dataset:\n",
    "    percent = str(int(100 * slider_size))\n",
    "    f = open('{}dataset/test_{}_{}.txt'.format(imagenet_root, type_str, percent), 'w')\n",
    "    test_files.append(f)\n",
    "\n",
    "    folder = '{}dataset/test_{}_{}/'.format(imagenet_root, type_str, percent)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    test_folders.append(folder)\n",
    "    \n",
    "if 'obj' in type_str:\n",
    "    obj_images = []\n",
    "    for i, image_name in enumerate(os.listdir(shapenet_root + 'object_crop/')):\n",
    "        img_temp = Image.open(shapenet_root + 'object_crop/' + image_name)\n",
    "        img = img_temp.copy()\n",
    "        img_temp.close()\n",
    "        #img = img.convert(\"RGBA\")\n",
    "        obj_images.append(img)\n",
    "    print \"{} object occluders loaded.\".format(len(obj_images))\n",
    "\n",
    "# occluder size = slider_size * slider_size\n",
    "# occluder num = slider_num * slider_num\n",
    "# path = 'imagenet_root/dataset/train_0/name'\n",
    "# {wnid_imgid}_{crop/nocrop}_{rect_i(ifcrop)}_{slider_size}_{i}_{j}\n",
    "def generate_datum(img_orig, path, f, class_id, rects, slider_size, slider_num):\n",
    "    if type_str == 'crop' or type_str == '1k_crop':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_0_0.jpeg'.format(path, type_str, rect_i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "                    d.rectangle(subrect, fill=mean_color, outline=None)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "    if type_str == 'nocrop' or type_str == '1k_nocrop':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_0_0_0.jpeg'.format(path, type_str)\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for i in range(slider_num):\n",
    "                img = img_orig.copy()\n",
    "                d = ImageDraw.Draw(img)\n",
    "                for rect in rects:\n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "                    d.rectangle(subrect, fill=mean_color, outline=None)\n",
    "                datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, 0, str(int(100 * slider_size)), i)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))   \n",
    "                \n",
    "                \n",
    "    if type_str == 'aperture' or type_str == '1k_aperture':\n",
    "        if slider_size == 0: # All gray.\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                d = ImageDraw.Draw(img)\n",
    "                d.rectangle(rect, fill=mean_color, outline=None)\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        elif slider_size == 1: # All visible. \n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for i in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    d = ImageDraw.Draw(img)\n",
    "                    \n",
    "                    slider_width = int((rect[2] - rect[0]) * math.sqrt(slider_size))\n",
    "                    slider_height = int((rect[3] - rect[1]) * math.sqrt(slider_size))\n",
    "                    \n",
    "                    subrect = [0, 0, 0, 0]\n",
    "                    subrect[0] = random.randint(rect[0], rect[2] - slider_width)\n",
    "                    subrect[1] = random.randint(rect[1], rect[3] - slider_height)\n",
    "                    subrect[2] = subrect[0] + slider_width\n",
    "                    subrect[3] = subrect[1] + slider_height\n",
    "\n",
    "                    d.rectangle([0, 0, img.size[0], subrect[1]], fill=mean_color, outline=None)\n",
    "                    d.rectangle([0, 0, subrect[0], img.size[1]], fill=mean_color, outline=None)\n",
    "                    d.rectangle([subrect[2], 0, img.size[0], img.size[1]], fill=mean_color, outline=None)\n",
    "                    d.rectangle([0, subrect[3], img.size[0], img.size[1]], fill=mean_color, outline=None)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, str(int(100 * slider_size)), i)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "    \n",
    "    # TODO no obj_ratio, obj_width, obj_height now\n",
    "    if type_str == 'crop_obj' or type_str == '1k_crop_obj':\n",
    "        if slider_size == 0:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                img = img_orig.copy()\n",
    "                img = img.crop(rect)\n",
    "                datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, rect_i, int(100 * slider_size))\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for rect_i, rect in enumerate(rects):\n",
    "                for num in range(slider_num):\n",
    "                    img = img_orig.copy()\n",
    "                    random_obj = obj_images[random.randint(0, len(obj_images) - 1)].copy()\n",
    "                    obj_width = random_obj.size[0]\n",
    "                    obj_height = random_obj.size[1]\n",
    "                    obj_ratio = float(obj_width) / obj_height\n",
    "                    \n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    \n",
    "                    max_occlusion = 0.0\n",
    "                    if ratio >= obj_ratio:\n",
    "                        max_occlusion = obj_width * height / float(width * obj_height)\n",
    "                    else:\n",
    "                        max_occlusion = width * obj_height / float(height * obj_width)\n",
    "                    \n",
    "                    if max_occlusion >= slider_size:\n",
    "                        # Do not need to stretch and change obj_ratio.\n",
    "                        new_width = (slider_size * width * height * obj_width / float(obj_height)) ** 0.5\n",
    "                        new_height = (slider_size * width * height * obj_height / float(obj_width)) ** 0.5\n",
    "                    else:\n",
    "                        # Need to stretch and change obj_ratio.\n",
    "                        if ratio >= obj_ratio:\n",
    "                            new_width = width * slider_size\n",
    "                            new_height = height\n",
    "                        else:\n",
    "                            new_width = width\n",
    "                            new_height = height * slider_size\n",
    "                    new_width = int(new_width)\n",
    "                    new_height = int(new_height)\n",
    "                    if new_width == 0:\n",
    "                        new_width = 1\n",
    "                    if new_height == 0:\n",
    "                        new_height = 1\n",
    "                        \n",
    "                    random_obj = random_obj.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "                    \n",
    "                    top_left = (random.randint(rect[0], rect[2] - random_obj.size[0]),\\\n",
    "                                random.randint(rect[1], rect[3] - random_obj.size[1]))\n",
    "                    \n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    img = img.crop(rect)\n",
    "                    datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                    img.save(datum_path)\n",
    "                    f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "                    \n",
    "    if type_str == 'nocrop_obj' or type_str == '1k_nocrop_obj':\n",
    "        if slider_size == 0:\n",
    "            datum_path = '{}_{}_{}_{}_0.jpeg'.format(path, type_str, 0, int(100 * slider_size))\n",
    "            img_orig.save(datum_path)\n",
    "            f.write('{} {}\\n'.format(datum_path, str(class_id)))\n",
    "        else:\n",
    "            for num in range(slider_num):\n",
    "                img = img_orig.copy()\n",
    "                for rect_i, rect in enumerate(rects):\n",
    "                    random_obj = obj_images[random.randint(0, len(obj_images) - 1)].copy()\n",
    "                    \n",
    "                    obj_width = random_obj.size[0]\n",
    "                    obj_height = random_obj.size[1]\n",
    "                    obj_ratio = float(obj_width) / obj_height\n",
    "                    \n",
    "                    width = rect[2] - rect[0]\n",
    "                    height = rect[3] - rect[1]\n",
    "                    ratio = float(width) / height\n",
    "                    \n",
    "                    max_occlusion = 0.0\n",
    "                    if ratio >= obj_ratio:\n",
    "                        max_occlusion = obj_width * height / float(width * obj_height)\n",
    "                    else:\n",
    "                        max_occlusion = width * obj_height / float(height * obj_width)\n",
    "                    \n",
    "                    if max_occlusion >= slider_size:\n",
    "                        # Do not need to stretch and change obj_ratio.\n",
    "                        new_width = (slider_size * width * height * obj_width / float(obj_height)) ** 0.5\n",
    "                        new_height = (slider_size * width * height * obj_height / float(obj_width)) ** 0.5\n",
    "                    else:\n",
    "                        # Need to stretch and change obj_ratio.\n",
    "                        if ratio >= obj_ratio:\n",
    "                            new_width = width * slider_size\n",
    "                            new_height = height\n",
    "                        else:\n",
    "                            new_width = width\n",
    "                            new_height = height * slider_size\n",
    "                    new_width = int(new_width)\n",
    "                    new_height = int(new_height)\n",
    "                    if new_width == 0:\n",
    "                        new_width = 1\n",
    "                    if new_height == 0:\n",
    "                        new_height = 1\n",
    "                        \n",
    "                    random_obj = random_obj.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "                    \n",
    "                    top_left = (random.randint(rect[0], rect[2] - random_obj.size[0]),\\\n",
    "                                random.randint(rect[1], rect[3] - random_obj.size[1]))\n",
    "                    \n",
    "                    img.paste(random_obj, top_left, random_obj)\n",
    "                    \n",
    "                datum_path = '{}_{}_{}_{}_{}.jpeg'.format(path, type_str, rect_i, int(100 * slider_size), num)\n",
    "                img.save(datum_path)\n",
    "                f.write('{} {}\\n'.format(datum_path, str(class_id))) \n",
    "            \n",
    "image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "annotation_path =  imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/'\n",
    "\n",
    "if '1k' in type_str:\n",
    "    synset_names = os.listdir(image_path)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dataset_sum = training_dataset_size + validation_dataset_size + test_dataset_size\n",
    "all_sum = len(synset_names) * dataset_sum\n",
    "print all_sum\n",
    "\n",
    "for synset_index, synset_name in enumerate(synset_names):\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    annotation_names = os.listdir(annotation_path + synset_name)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    for i in range(dataset_sum):\n",
    "        if (i + 1) % 50 == 0:\n",
    "            second = int(time.time() - start_time)\n",
    "            now_time = time.strftime(\"%H:%M:%S\", time.gmtime(second))\n",
    "            now_sum = synset_index * dataset_sum + i\n",
    "            \n",
    "            estimated = int(float(all_sum) / now_sum * second)\n",
    "            estimated_time = time.strftime(\"%H:%M:%S\", time.gmtime(estimated))\n",
    "            estimated_day = estimated / 3600 / 24\n",
    "            print '[{}/{} {}]Processing synset [{}/{}], image [{}/{}]: {}'.format(now_time, estimated_day, estimated_time, synset_index + 1, len(synset_names), i + 1, dataset_sum, intersection_names[i])\n",
    "        # Read bounding box.\n",
    "        bbx_file = open(annotation_path + synset_name + '/' + intersection_names[i] + '.xml')\n",
    "        xmltree = ET.parse(bbx_file)\n",
    "        objects = xmltree.findall('object')\n",
    "        rects = []\n",
    "        for obj in objects:\n",
    "            bbx = obj.find('bndbox')\n",
    "            rects.append([int(it.text) for it in bbx])\n",
    "            \n",
    "        img_orig = Image.open(image_path + synset_name + '/' + intersection_names[i] + '.JPEG')\n",
    "        if img_orig.mode != \"RGB\":\n",
    "            img_orig = img_orig.convert(\"RGB\")\n",
    "            \n",
    "        if '1k' in type_str:\n",
    "            class_id = wnid_to_label[synset_name]\n",
    "        else:\n",
    "            class_id = original_to_new_class_id[wnid_to_label[synset_name]]\n",
    "        \n",
    "        if i < training_dataset_size: # Training dataset. \n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(train_folders[index], intersection_names[i]), \\\n",
    "                               train_files[index], class_id, rects, slider_size, slider_num)\n",
    "        elif i < training_dataset_size + validation_dataset_size: # Validation dataset\n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(val_folders[index], intersection_names[i]), \\\n",
    "                               val_files[index], class_id, rects, slider_size, slider_num)\n",
    "        else: # Test dataset.\n",
    "            for index, (slider_size, slider_num) in enumerate(dataset):\n",
    "                generate_datum(img_orig, '{}{}'.format(test_folders[index], intersection_names[i]), \\\n",
    "                               test_files[index], class_id, rects, slider_size, slider_num)\n",
    "                               \n",
    "for f in train_files:\n",
    "    f.close()\n",
    "for f in test_files:\n",
    "    f.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample or for lmdb.\n",
    "\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "import shutil\n",
    "\n",
    "mode = 'nosample'\n",
    "is_lmdb = True\n",
    "\n",
    "func_strs = ['train', 'val', 'test']\n",
    "type_strs = ['crop_obj']\n",
    "names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100']\n",
    "sample_sum = {'train': 100000, 'test': 50000}\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        for name in names:\n",
    "            #shutil.copyfile('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), \\\n",
    "            #         '{}dataset/{}_{}_{}_unsampled.txt'.format(imagenet_root, func_str, type_str, name))\n",
    "            with open('{}dataset/{}_{}_{}_unsampled.txt'.format(imagenet_root, func_str, type_str, name)) as f:\n",
    "                lines = f.readlines()\n",
    "            if mode == 'nosample':\n",
    "                sampled = lines\n",
    "            else:\n",
    "                sampled = random.sample(lines, sample_sum[func_str])\n",
    "            if is_lmdb:\n",
    "                for i in range(len(sampled)):\n",
    "                    sampled[i] = sampled[i].split('/')[-2] + '/' + sampled[i].split('/')[-1]\n",
    "            with open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name), 'w') as f:\n",
    "                f.writelines(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create {}_{}_all.txt.\n",
    "import os\n",
    "import random\n",
    "from constant import *\n",
    "\n",
    "func_strs = ['train', 'val', 'test']\n",
    "type_strs = ['every']\n",
    "names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100']\n",
    "#names = ['0', '20', '40', '60', '80', '100']\n",
    "\n",
    "#sample_sum = {'train': {'crop': 343360, 'nocrop': 300000}, \\\n",
    "#              'val': {'crop': 114010, 'nocrop': 100000}, \\\n",
    "#              'test': {'crop': 114060, 'nocrop': 100000}}\n",
    "\n",
    "#sample_sum = {'train': {'aperture': 343360}, \\\n",
    "#              'val': {'aperture': 114010}, \\\n",
    "#              'test': {'aperture': 114060}}\n",
    "\n",
    "#sample_sum = {'train': {'crop_obj': 343360}, \\\n",
    "#              'val': {'crop_obj': 114010}, \\\n",
    "#              'test': {'crop_obj': 114060}}\n",
    "\n",
    "\n",
    "sample_sum = {'train': {'every': 343360}, \\\n",
    "              'val': {'every': 114010}, \\\n",
    "              'test': {'every': 114060}}\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        lines = []\n",
    "        for data_name in ['crop', 'aperture', 'crop_obj']:\n",
    "            for name in names:\n",
    "                f = open('{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, data_name, name), 'r')\n",
    "                ls = f.readlines()\n",
    "                f.close()\n",
    "                lines = lines + ls\n",
    "        f = open('{}dataset/{}_{}_all_unsampled.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        sampled = random.sample(lines, sample_sum[func_str][type_str])\n",
    "        f = open('{}dataset/{}_{}_all.txt'.format(imagenet_root, func_str, type_str), 'w')\n",
    "        f.writelines(sampled)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_0.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_10.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_20.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_30.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_40.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_50.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_60.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_70.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_80.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_90.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_100.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_all.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_aperture_0.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_10.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_20.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_30.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_40.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_50.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_60.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_70.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_80.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_90.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_aperture_100.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_aperture_all.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_obj_0.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_10.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_20.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_30.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_40.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_50.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_60.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_70.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_80.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_90.txt\n",
      "     34336 /data2/haow3/data/imagenet/dataset/train_crop_obj_100.txt\n",
      "    343360 /data2/haow3/data/imagenet/dataset/train_crop_obj_all.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_0.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_10.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_20.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_30.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_40.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_50.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_60.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_70.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_80.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_90.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_100.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_all.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_aperture_0.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_10.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_20.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_30.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_40.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_50.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_60.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_70.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_80.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_90.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_aperture_100.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_aperture_all.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_obj_0.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_10.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_20.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_30.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_40.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_50.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_60.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_70.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_80.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_90.txt\n",
      "     11401 /data2/haow3/data/imagenet/dataset/val_crop_obj_100.txt\n",
      "    114010 /data2/haow3/data/imagenet/dataset/val_crop_obj_all.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_0.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_10.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_20.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_30.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_40.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_50.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_60.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_70.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_80.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_90.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_100.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_all.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_aperture_0.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_10.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_20.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_30.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_40.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_50.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_60.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_70.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_80.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_90.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_aperture_100.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_aperture_all.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_obj_0.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_10.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_20.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_30.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_40.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_50.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_60.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_70.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_80.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_90.txt\n",
      "     11406 /data2/haow3/data/imagenet/dataset/test_crop_obj_100.txt\n",
      "    114060 /data2/haow3/data/imagenet/dataset/test_crop_obj_all.txt\n"
     ]
    }
   ],
   "source": [
    "# Sanity check.\n",
    "import os\n",
    "from constant import *\n",
    "\n",
    "func_strs = ['train', 'val', 'test']\n",
    "type_strs = ['crop', 'aperture', 'crop_obj']\n",
    "names = ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100', 'all']\n",
    "\n",
    "for func_str in func_strs:\n",
    "    for type_str in type_strs:\n",
    "        for name in names:\n",
    "            filename = '{}dataset/{}_{}_{}.txt'.format(imagenet_root, func_str, type_str, name) \n",
    "            f = open(filename)\n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            print '{:10d} {}'.format(len(lines), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%file transparent.py\n",
    "# Make white color transparent and crop bounding box. For nocrop_obj/crop_obj.\n",
    "from constant import *\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_names = os.listdir(shapenet_root + 'object_orig/')\n",
    "print len(image_names)\n",
    "\n",
    "ratio = []\n",
    "\n",
    "for i, image_name in enumerate(image_names):\n",
    "    print '[{}/{}]: {}'.format(i, len(image_names), image_name)\n",
    "    img = Image.open(shapenet_root + 'object_orig/' + image_name)\n",
    "    \n",
    "    img = img.convert(\"RGBA\")\n",
    "    pixdata = img.load()\n",
    "    \n",
    "    scanline_x = np.zeros(img.size[0])\n",
    "    scanline_y = np.zeros(img.size[1])\n",
    "    \n",
    "    for x in xrange(img.size[0]):\n",
    "        for y in xrange(img.size[1]):\n",
    "            if pixdata[x, y] == (255, 255, 255, 255):\n",
    "                pixdata[x, y] = (255, 255, 255, 0)\n",
    "            else:\n",
    "                scanline_x[x] = 1\n",
    "                scanline_y[y] = 1\n",
    "                \n",
    "    # Get bounding box.\n",
    "    rect = [0, 0, 0, 0]\n",
    "    for i in range(len(scanline_x)):\n",
    "        if scanline_x[i] != 0:\n",
    "            rect[0] = i\n",
    "            break\n",
    "    for i in range(len(scanline_x)):\n",
    "        if scanline_x[len(scanline_x) - i - 1] != 0:\n",
    "            rect[2] = len(scanline_x) - i - 1\n",
    "            break\n",
    "    for i in range(len(scanline_y)):\n",
    "        if scanline_y[i] != 0:\n",
    "            rect[1] = i\n",
    "            break\n",
    "    for i in range(len(scanline_y)):\n",
    "        if scanline_y[len(scanline_y) - i - 1] != 0:\n",
    "            rect[3] = len(scanline_y) - i - 1\n",
    "            break\n",
    "            \n",
    "    ratio.append((rect[2] - rect[0]) / (rect[3] - rect[1]))\n",
    "            \n",
    "    img = img.crop(rect)\n",
    "            \n",
    "    img.save(shapenet_root + 'object_crop/' + image_name, 'PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from constant import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f = open(caffe_root + 'data/ilsvrc12/synset_words.txt')\n",
    "label_to_wnid = f.readlines()\n",
    "wnid_to_label = {}\n",
    "for label in range(len(label_to_wnid)):\n",
    "    wnid = label_to_wnid[label].split(' ')[0]\n",
    "    wnid_to_label[wnid] = label\n",
    "\n",
    "folders = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/')\n",
    "count = []\n",
    "for folder in folders:\n",
    "    image_names = os.listdir(imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/' + folder)\n",
    "    annotation_names = os.listdir(imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/' + folder)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    count.append(len(intersection_names))\n",
    "\n",
    "x = [i for i in range(len(count))]\n",
    "count = sorted(count)\n",
    "plt.plot(x, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Randomly sample classes for experiment.\n",
    "import os\n",
    "from constant import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "label_to_wnid = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "\n",
    "synset_name_to_original_id = {}\n",
    "for original_id in range(len(label_to_wnid)):\n",
    "    synset_name = label_to_wnid[original_id].split(' ')[0]\n",
    "    synset_name_to_original_id[synset_name] = original_id\n",
    "\n",
    "image_path = imagenet_root + 'ILSVRC2015/Data/CLS-LOC/train/'\n",
    "annotation_path =  imagenet_root + 'ILSVRC2015/Annotations/CLS-LOC/train/'\n",
    "\n",
    "count = []\n",
    "sampled = []\n",
    "for synset_index, synset_name in enumerate(os.listdir(image_path)):\n",
    "    image_names = os.listdir(image_path + synset_name)\n",
    "    annotation_names = os.listdir(annotation_path + synset_name)\n",
    "    n1 = [os.path.splitext(n)[0] for n in image_names]\n",
    "    n2 = [os.path.splitext(n)[0] for n in annotation_names]\n",
    "    intersection_names = list(set(n1) & set(n2))\n",
    "    count.append(len(intersection_names))\n",
    "    if len(intersection_names) >= 500:\n",
    "        sampled.append(synset_name)\n",
    "\n",
    "count = sorted(count)\n",
    "plt.plot(count)\n",
    "\n",
    "sampled = random.sample(sampled, 100)\n",
    "print sampled\n",
    "\n",
    "new_to_original_class_id = []\n",
    "original_to_new_class_id = {}\n",
    "for synset_name in sampled:\n",
    "    new_to_original_class_id.append(synset_name_to_original_id[synset_name])\n",
    "new_to_original_class_id = sorted(new_to_original_class_id)\n",
    "print new_to_original_class_id\n",
    "\n",
    "for i, original_id in enumerate(new_to_original_class_id):\n",
    "    original_to_new_class_id[original_id] = i\n",
    "print original_to_new_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate label list.\n",
    "import os\n",
    "from constant import *\n",
    "\n",
    "imagenet_labels_filename = imagenet_root + 'ilsvrc12/synset_words.txt'\n",
    "lines = open(imagenet_labels_filename).readlines()\n",
    "\n",
    "original_id_to_name = []\n",
    "for line in lines:\n",
    "    wnid = line.split(' ')[0]\n",
    "    name = line[(len(wnid) + 1):-1]\n",
    "    original_id_to_name.append(name)\n",
    "    \n",
    "    \n",
    "label = [None for i in range(len(synset_names))]\n",
    "\n",
    "for new_id, original_id in enumerate(new_to_original_class_id):\n",
    "    label[new_id] = original_id_to_name[original_id]\n",
    "    print label[new_id]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
